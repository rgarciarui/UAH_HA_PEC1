{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción-al-dataset-Fashion-Mnist\" data-toc-modified-id=\"Introducción-al-dataset-Fashion-Mnist-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción al dataset Fashion-Mnist</a></span><ul class=\"toc-item\"><li><span><a href=\"#Jugando-con-la-moda-MNIST\" data-toc-modified-id=\"Jugando-con-la-moda-MNIST-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Jugando con la moda MNIST</a></span></li><li><span><a href=\"#Entrar-en-la-moda-MNIST\" data-toc-modified-id=\"Entrar-en-la-moda-MNIST-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Entrar en la moda MNIST</a></span></li></ul></li><li><span><a href=\"#Métodos-supervisados\" data-toc-modified-id=\"Métodos-supervisados-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Métodos supervisados</a></span><ul class=\"toc-item\"><li><span><a href=\"#Carga-de-datos\" data-toc-modified-id=\"Carga-de-datos-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Carga de datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descripción-del-conjunto-de-datos\" data-toc-modified-id=\"Descripción-del-conjunto-de-datos-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Descripción del conjunto de datos</a></span></li><li><span><a href=\"#Definición-del-conjunto-de-entrenamiento-y-test\" data-toc-modified-id=\"Definición-del-conjunto-de-entrenamiento-y-test-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Definición del conjunto de entrenamiento y test</a></span></li><li><span><a href=\"#Utilización-de-algoritmo-PCA-para-reducción-dimensión-del-dataset\" data-toc-modified-id=\"Utilización-de-algoritmo-PCA-para-reducción-dimensión-del-dataset-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Utilización de algoritmo PCA para reducción dimensión del dataset</a></span></li></ul></li><li><span><a href=\"#$k$-vecinos-más-cercanos\" data-toc-modified-id=\"$k$-vecinos-más-cercanos-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>$k$ vecinos más cercanos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cálculo-hiperparámetros-óptimos\" data-toc-modified-id=\"Cálculo-hiperparámetros-óptimos-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Cálculo hiperparámetros óptimos</a></span></li><li><span><a href=\"#Entrenamiento-de-un-modelo-$k$-nn\" data-toc-modified-id=\"Entrenamiento-de-un-modelo-$k$-nn-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Entrenamiento de un modelo $k$-nn</a></span></li><li><span><a href=\"#La-matriz-de-confusión\" data-toc-modified-id=\"La-matriz-de-confusión-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>La matriz de confusión</a></span></li></ul></li><li><span><a href=\"#Support-Vector-Machines\" data-toc-modified-id=\"Support-Vector-Machines-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Support Vector Machines</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cálculo-del-valor-óptimo-de-hiperparámetros\" data-toc-modified-id=\"Cálculo-del-valor-óptimo-de-hiperparámetros-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Cálculo del valor óptimo de hiperparámetros</a></span></li></ul></li><li><span><a href=\"#3.-Redes-neuronales-(4-puntos)\" data-toc-modified-id=\"3.-Redes-neuronales-(4-puntos)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>3. Redes neuronales (4 puntos)</a></span></li><li><span><a href=\"#4.-Optimización-de-métricas-(2-puntos)\" data-toc-modified-id=\"4.-Optimización-de-métricas-(2-puntos)-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>4. Optimización de métricas (2 puntos)</a></span></li></ul></li><li><span><a href=\"#PEC-4:-Combinación-de-clasificadores\" data-toc-modified-id=\"PEC-4:-Combinación-de-clasificadores-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>PEC 4: Combinación de clasificadores</a></span></li><li><span><a href=\"#0.-Carga-de-datos\" data-toc-modified-id=\"0.-Carga-de-datos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>0. Carga de datos</a></span></li><li><span><a href=\"#1.-Combinación-paralela-de-clasificadores-base-similares\" data-toc-modified-id=\"1.-Combinación-paralela-de-clasificadores-base-similares-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>1. Combinación paralela de clasificadores base similares</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Bagging\" data-toc-modified-id=\"1.1-Bagging-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>1.1 Bagging</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1.1-Random-forest-simple-(1-punto)\" data-toc-modified-id=\"1.1.1-Random-forest-simple-(1-punto)-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>1.1.1 Random forest simple (1 punto)</a></span></li><li><span><a href=\"#1.1.2-Out-of-bag-(1-punto)\" data-toc-modified-id=\"1.1.2-Out-of-bag-(1-punto)-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>1.1.2 Out-of-bag (1 punto)</a></span></li><li><span><a href=\"#1.1.3-Probabilidad-por-clase-(1-punto)\" data-toc-modified-id=\"1.1.3-Probabilidad-por-clase-(1-punto)-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>1.1.3 Probabilidad por clase (1 punto)</a></span></li><li><span><a href=\"#1.1.4-Importancia-de-las-variables-(1-punto)\" data-toc-modified-id=\"1.1.4-Importancia-de-las-variables-(1-punto)-5.1.4\"><span class=\"toc-item-num\">5.1.4&nbsp;&nbsp;</span>1.1.4 Importancia de las variables (1 punto)</a></span></li><li><span><a href=\"#1.1.5-Número-de-clasificadores-(1-punto)\" data-toc-modified-id=\"1.1.5-Número-de-clasificadores-(1-punto)-5.1.5\"><span class=\"toc-item-num\">5.1.5&nbsp;&nbsp;</span>1.1.5 Número de clasificadores (1 punto)</a></span></li><li><span><a href=\"#1.1.6-Volumen-de-datos-(1-punto)\" data-toc-modified-id=\"1.1.6-Volumen-de-datos-(1-punto)-5.1.6\"><span class=\"toc-item-num\">5.1.6&nbsp;&nbsp;</span>1.1.6 Volumen de datos (1 punto)</a></span></li></ul></li><li><span><a href=\"#1.2-Boosting-(1-punto)\" data-toc-modified-id=\"1.2-Boosting-(1-punto)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>1.2 Boosting (1 punto)</a></span></li></ul></li><li><span><a href=\"#2.-Combinación-secuencial-de-clasificadores-base-diferentes\" data-toc-modified-id=\"2.-Combinación-secuencial-de-clasificadores-base-diferentes-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>2. Combinación secuencial de clasificadores base diferentes</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Stacking-(1-punto)\" data-toc-modified-id=\"2.1-Stacking-(1-punto)-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>2.1 Stacking (1 punto)</a></span></li><li><span><a href=\"#2.2-Cascading\" data-toc-modified-id=\"2.2-Cascading-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>2.2 Cascading</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.2.1-Cascading-simple-(1-punto)\" data-toc-modified-id=\"2.2.1-Cascading-simple-(1-punto)-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>2.2.1 Cascading simple (1 punto)</a></span></li><li><span><a href=\"#2.2.2-Cascading-con-variables-adicionales-(1-punto)\" data-toc-modified-id=\"2.2.2-Cascading-con-variables-adicionales-(1-punto)-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>2.2.2 Cascading con variables adicionales (1 punto)</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"https://biblioteca.uah.es/imgs/logo11.png\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">EN26 - HERRAMIENTAS DE ANÁLISIS · PEC1</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">ENTORNOS DE ANÁLISIS DE DATOS (PYTHON)  </p>\n",
    "<p style=\"margin: 0; text-align:right;\">2018-2019 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Introducción al dataset Fashion-Mnist\n",
    "\n",
    "## Jugando con la moda MNIST\n",
    "<div>\n",
    "<br><p>Recientemente, los investigadores de <b>Zalando</b>, una empresa de comercio electrónico, presentaron a Fashion MNIST como un reemplazo directo del conjunto de datos original de MNIST. Al igual que MNIST, <b>Fashion MNIST</b> consiste en un conjunto de entrenamiento que consiste en 60.000 ejemplos pertenecientes a 10 clases diferentes y un conjunto de prueba de 10.000 ejemplos. Cada ejemplo de entrenamiento es una imagen en escala de grises, de tamaño 28x28.</p></div>\n",
    "    \n",
    "## Entrar en la moda MNIST\n",
    "<div><br><p>Al publicar este conjunto de datos, los investigadores de Zalando hicieron las siguientes observaciones en MNIST:</p>\n",
    "\n",
    "<ol start=\"0\"><i>\n",
    "<li>MNIST es demasiado fácil. Las redes convolucionales pueden alcanzar el 99.7% en MNIST. Los algoritmos clásicos de aprendizaje automático también pueden alcanzar el 97% fácilmente. Echa un vistazo a nuestro punto de referencia de lado a lado para Fashion-MNIST vs. MNIST, y lee \"La mayoría de los pares de dígitos MNIST se pueden distinguir bastante bien con solo un píxel\".</li>\n",
    "<li>MNIST está sobreutilizado. En un hilo de Twitter de abril de 2017, el investigador científico de <b>Google Brain</b> y experto en aprendizaje profundo, Ian Goodfellow, hizo un llamamiento a los investigadores a alejarse del conjunto MNIST.</li>\n",
    "<li>MNIST no puede representar tareas CV modernas , como se señala en este hilo de Twitter de abril de 2017, el experto en aprendizaje profundo/autor de Keras, François Chollet.</li>\n",
    "    </i></ol>\n",
    "   <p>Los investigadores introdujeron a Fashion-MNIST como un reemplazo del conjunto de datos MNIST. El nuevo conjunto de datos contiene imágenes de diversos artículos de ropa, como camisas, zapatos, abrigos y otros artículos de moda.</p>\n",
    "   <p><img src=\"https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png\", align=\"cener\"></p>\n",
    "   <p>El dataset Fashion-MNIST comparte la misma estructura dividida de train-test como MNIST. Mientras que en el caso del conjunto de datos MNIST las etiquetas de clase eran dígitos del 0-9, Las etiquetas de clase para Fashion-MNIST son las siguientes:\n",
    "</p>\n",
    "<p><table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Label</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>T-shirt/top</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>Trouser</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>2</td>\n",
    "<td>Pullover</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>3</td>\n",
    "<td>Dress</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>4</td>\n",
    "<td>Coat</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>5</td>\n",
    "<td>Sandal</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>6</td>\n",
    "<td>Shirt</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>7</td>\n",
    "<td>Sneaker</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>8</td>\n",
    "<td>Bag</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>9</td>\n",
    "<td>Ankle boot</td>\n",
    "</tr>\n",
    "    </table></p>\n",
    "   </div>\n",
    "   <br>\n",
    "<div>\n",
    "\n",
    "# Métodos supervisados\n",
    "\n",
    "En esta primera parte de la práctica vamos a trabajar en diferentes métodos supervisados aplicados sobre el conjunto de datos [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) y trataremos de optimizar diferentes métricas.\n",
    "\n",
    "<ol start=\"0\">\n",
    "  <li>Carga de datos</li>\n",
    "  <li>$k$ vecinos más cercanos</li>\n",
    "  <li>Support vector machines</li>\n",
    "  <li>Redes neuronales</li>\n",
    "  <li>Optimización de métricas</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "### Descripción del conjunto de datos\n",
    "\n",
    "El conjunto de datos Fashion MNIST proporcionado por Zalando consta de 70.000 imágenes con 10 clases diferentes de ropa repartidas uniformemente. No obstante, para esta práctica utilizaremos únicamente un subconjunto de 5.000 imágenes que consiste en 1.000 imágenes de 5 clases diferentes.\n",
    "\n",
    "Las imágenes tienen una resolución de 28x28 píxeles en escala de grises, por lo que se pueden representar utilizando un vector de 784 posiciones.\n",
    "\n",
    "El siguiente código cargará las 5.000 imágenes en la variable images y las correspondientes etiquetas (en forma numérica) en la variable labels. Podemos comprobar que la carga ha sido correcta obteniendo las dimensiones de estas dos variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del vector de imágenes: (5000, 784)\n",
      "Dimensiones del vector de etiquetas: (5000,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "images = data[\"images\"]\n",
    "labels = data[\"labels\"]\n",
    "n_classes = 5\n",
    "labels_text = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\"]\n",
    "\n",
    "print(\"Dimensiones del vector de imágenes: {}\".format(images.shape))\n",
    "print(\"Dimensiones del vector de etiquetas: {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el siguiente código podemos ver un ejemplo de imagen de cada una de las clases. Para ello reajustamos el vector de 784 dimensiones que representa cada imagen en una matriz de tamaño 28x28 y la transponemos para mostrarla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where(labels == i)[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(images[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"{}\".format(labels_text[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del conjunto de entrenamiento y test\n",
    "\n",
    "De las 5.000 imágenes distintas de subset de datos utilizaremos 4.000 imágenes para entrenar los diferentes modelos y 1.000 imágenes para validar los resultados. Con el siguiente código separamos los datos que hemos cargado anteriormente en dos conjuntos, train y test, de forma estratificada, es decir, en cada uno de los conjuntos las clases aparecen en la misma proporción que en el conjunto original.\n",
    "\n",
    "### Utilización de algoritmo PCA para reducción dimensión del dataset\n",
    "\n",
    "En lugar de trabajar directamente con un vector de 784 dimensiones para cada imagen aplicaremos primero el algoritmo PCA para reducir la dimensión de los ejemplos a 100. El proceso de entrenamiento de PCA lo hacemos con las imágenes de train y luego lo aplicamos también sobre las imágenes de test, de forma que no utilizamos ninguna información de las imágenes en el conjunto de test para entrenar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes para entrenar: 4000\n",
      "Número de imágenes para test: 1000\n",
      "Proporción de las etiquetas en el conjunto original: [0.2 0.2 0.2 0.2 0.2]\n",
      "Proporción de las etiquetas en el conjunto de entrenamiento: [0.2 0.2 0.2 0.2 0.2]\n",
      "Proporción de las etiquetas en el conjunto de test: [0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=2017, stratify=labels)\n",
    "\n",
    "pca = PCA(n_components=100, random_state=2017)\n",
    "pca_fit = pca.fit(X_train)\n",
    "X_train_pca = pca_fit.transform(X_train)\n",
    "X_test_pca = pca_fit.transform(X_test)\n",
    "\n",
    "def proporcion_etiquetas(y):\n",
    "    _, count = np.unique(y, return_counts=True)\n",
    "    return np.true_divide(count, y.shape[0])\n",
    "    \n",
    "\n",
    "print(\"Número de imágenes para entrenar: {}\".format(X_train_pca.shape[0]))\n",
    "print(\"Número de imágenes para test: {}\".format(X_test_pca.shape[0]))\n",
    "\n",
    "print(\"Proporción de las etiquetas en el conjunto original: {}\".format(proporcion_etiquetas(labels)))\n",
    "print(\"Proporción de las etiquetas en el conjunto de entrenamiento: {}\".format(proporcion_etiquetas(y_train)))\n",
    "print(\"Proporción de las etiquetas en el conjunto de test: {}\".format(proporcion_etiquetas(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$ vecinos más cercanos\n",
    "\n",
    "El primer algoritmo que utilizaremos para clasificar las imágenes de ropa es el  $k$-nn. En este paso del análisis del dataset ajustaremos dos hiperparámetros del algoritmo:\n",
    "\n",
    "<ol><i>\n",
    "<li>$k$: el número de vecinos que se consideran para clasificar un nuevo ejemplo. Probaremos con todos los valores entre 1 y 10.</li>\n",
    "<li>pesos: importancia que se da a cada uno de los vecinos considerados. En este caso probaremos dos opciones: </li>\n",
    "    <ol>    \n",
    "    <li>pesos uniformes, donde todos los vecinos se consideran igual</li>\n",
    "    <li>pesos según distancia, donde los vecinos más cercanos tienen más peso en la clasificación que los vecinos más lejanos.</li>\n",
    "    </ol>\n",
    "</ol>\n",
    "\n",
    "Para decidir cuáles son los hiperparámetros óptimos utilizaremos una búsqueda de rejilla (grid search), es decir, entrenaremos un modelo para cada combinación de hiperparámetros posible y la evaluaremos utilizando validación cruzada (cross validation) con 4 particiones estratificadas. Posteriormente escogeremos la combinación de hiperparámetros que mejor resultados haya dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo hiperparámetros óptimos\n",
    "<br>\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<p><strong>Implementación:</strong> Calcularemos el valor óptimo de los hiperparámetros $k$ y pesos. Vamos a utilizar los módulos GridSearchCV y KNeighborsClassifier de sklearn.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La búsqueda llevó 65.81802892684937 segundos\n",
      "17) Precisión media: 83.55 +/- 1.32 con parámetros {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "17) Precisión media: 83.55 +/- 1.32 con parámetros {'n_neighbors': 1, 'weights': 'distance'}\n",
      "20) Precisión media: 82.53 +/- 1.10 con parámetros {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "17) Precisión media: 83.55 +/- 1.32 con parámetros {'n_neighbors': 2, 'weights': 'distance'}\n",
      "15) Precisión media: 85.20 +/- 0.78 con parámetros {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "13) Precisión media: 85.38 +/- 0.66 con parámetros {'n_neighbors': 3, 'weights': 'distance'}\n",
      "16) Precisión media: 84.92 +/- 0.78 con parámetros {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "10) Precisión media: 85.58 +/- 0.61 con parámetros {'n_neighbors': 4, 'weights': 'distance'}\n",
      "2) Precisión media: 85.95 +/- 0.86 con parámetros {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "4) Precisión media: 85.90 +/- 0.87 con parámetros {'n_neighbors': 5, 'weights': 'distance'}\n",
      "12) Precisión media: 85.40 +/- 0.91 con parámetros {'n_neighbors': 6, 'weights': 'uniform'}\n",
      "1) Precisión media: 86.10 +/- 0.72 con parámetros {'n_neighbors': 6, 'weights': 'distance'}\n",
      "8) Precisión media: 85.70 +/- 0.63 con parámetros {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "2) Precisión media: 85.95 +/- 0.82 con parámetros {'n_neighbors': 7, 'weights': 'distance'}\n",
      "11) Precisión media: 85.55 +/- 1.09 con parámetros {'n_neighbors': 8, 'weights': 'uniform'}\n",
      "4) Precisión media: 85.90 +/- 0.79 con parámetros {'n_neighbors': 8, 'weights': 'distance'}\n",
      "13) Precisión media: 85.38 +/- 1.13 con parámetros {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "6) Precisión media: 85.82 +/- 1.24 con parámetros {'n_neighbors': 9, 'weights': 'distance'}\n",
      "9) Precisión media: 85.65 +/- 1.01 con parámetros {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "6) Precisión media: 85.82 +/- 0.93 con parámetros {'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from time import time\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "            \n",
    "param_grid = {\"n_neighbors\": range(1, 11), \"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=4)\n",
    "\n",
    "start = time()\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "end = time()\n",
    "\n",
    "print(\"La búsqueda llevó {} segundos\".format(end - start))\n",
    "\n",
    "means = grid_search.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_search.cv_results_[\"std_test_score\"]\n",
    "params = grid_search.cv_results_['params']\n",
    "ranks = grid_search.cv_results_['rank_test_score']\n",
    "\n",
    "for rank, mean, std, pms in zip(ranks, means, stds, params):\n",
    "    print(\"{}) Precisión media: {:.2f} +/- {:.2f} con parámetros {}\".format(rank, mean*100, std*100, pms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> A partir de los resultados anteriores podemos considerar responder de manera sencilla las siguientes cuestiones:\n",
    "<ol>\n",
    "    <li>¿Qué parámetros han dado mejores resultados?</li>\n",
    "        <li>¿Qué variación hay entre las diferentes combinaciones de parámetros?</li>\n",
    "            <li>¿Es significativa la variación entre las diferentes combinaciones?</li>\n",
    "                <li>¿Hay algún parámetro que influya más que el otro?</li>\n",
    "                    <li>¿Era de esperar?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    <ul>\n",
    "<li>La mejor solución es con k = 6 y los pesos calculados con la distancia.\n",
    "<li>La máxima diferencia ente las precisiones medias es de unos 3.5 puntos porcentuales, con desviaciones estandard del orden de 1 punto porcentual podemos afirmar que hay opciones claramente mejores que otras.\n",
    "<li>Para k = 1 los pesos no importan, ya que siempre se clasifican los nuevos ejemplos con la clase del vecino más cercano.\n",
    "<li>Parece que la precisión depende más de k que del tipo de los pesos, aún así es interesante notar que en prácticamente todos los casos es mejor utilizar pesos con distancias en vez de uniformes, lo cual es lógico porque al utilizar las distancias el algoritmo tiene más información.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de un modelo $k$-nn\n",
    "<br>\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Ahora procederemos a realizar un entrenamiento de un modelo $k$-nn con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostraremos la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "La codificación siguiente realiza el entrenamiento $k$-nn, y finalmente muestra la precisión del conjunto de test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor óptimo para k: 6\n",
      "Valor óptimo para weights: distance\n",
      "Precisión en el conjunto de test: 86.60%\n"
     ]
    }
   ],
   "source": [
    "print(\"Valor óptimo para k: {}\".format(grid_search.best_params_[\"n_neighbors\"]))\n",
    "print(\"Valor óptimo para weights: {}\".format(grid_search.best_params_[\"weights\"]))\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=grid_search.best_params_[\"n_neighbors\"], weights=grid_search.best_params_[\"weights\"])\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_pca)\n",
    "\n",
    "accuracy = np.true_divide(np.sum(preds == y_test), preds.shape[0])*100\n",
    "print(\"Precisión en el conjunto de test: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La matriz de confusión\n",
    "<br>\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Finalmente mostramos la matriz de confusión del modelo y algunas imágenes que el modelo ha clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAEmCAYAAAAqWvi2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xd8VFX6x/HPk4QukARUyIQOkkInQQWUIiKY0KSKUi27KgiWXV1dUdG1gb38dHctyKIgzRA6IriiQhJ6VYKAZIKFiKCiCRnO7487hJlkIBOZluzz9jWv18ydc+98c708c+bMnXvEGINSSqnACQt2AKWU+l+jhVcppQJMC69SSgWYFl6llAowLbxKKRVgWniVUirAtPAqpVSAaeFVSqkA08KrlFIBFhHsAKFGKtcwUjU62DG81r7FxcGOUCaOcvZLSUGCHaHMpJxF3rxp4xFjzIW+2l54rUbGFP7mVVvz2w8rjDF9fPXa3tLCW4xUjabKZZOCHcNrny29N9gRyuSX3wuDHaFMIsLKWRUDKkeUrw+yNaqEHfTl9kzh71SJG+FV2983v1zXl6/tLS28SqmKRQj5br8WXqVUxSOh3evXwquUqni0x6uUUoEk2uNVSqmAEiAsPNgpzkkLr1KqghEdalBKqYDToQallAow7fEqpVQg6ZdrSikVWPoDCqWUCjSBsNAubaGdTiml/ogQv8aGFl6lVMUihPwYb2inKyeuTmrM1jfHs+Ptm7h3eKcSzze4sCbLnxnGF6+NIuP1MVyT3ASAShFhvHFPHzLfGMOG/xvNFW0aBCTvyhXLaZPYksS45kx75qkSz+fn53PjyOEkxjXnis6XcvDAgaLnpj39JIlxzWmT2JJVK1cEJO/qVSu4rH0iyW3jePHZZzzmvXnMSJLbxnFNj858c/BM3p07ttG3Z1e6Jrflykvb8fvvv/s970crl5PcLoEOrVvy/PSnPeYdP/p6OrRuSa9ul7vlBTh06BtiL6rNyy886/esYB0P7VrF0Tq+BdOneT4eRt8wgtbxLejW9bKi4yEvL4++vXtyUXRN7p40ISBZvSbi3S1ItPCep7Aw4YUJvRjw4Hza3/I2Q7vHEdewjlub+264jPn//ZLLb5/J6CcW8+LEXgCM79sGgOQ/zSD1b/N46k/d/H4sOBwOJt95B2npy9i8bRdzZ7/P7l273Nq889abREVGsXNPNhMn3cWDD9wHwO5du5g7Zzabtu5k0eLlTJp4Ow6Hw+9577/nTmYvSOezzG0snDebL/e455317ltERkaSuXUPf75jElOnPABAYWEht988hmkvvsq6zK18uHQ1lSpV8nvev9x9J3MXLmb9xu3MnzuHPbvd886c8Ra1I6PYtP1LbpswmUce+pvb8w/edw+9egfmErEOh4O7J01g4aKlbNy6k7lzZrO7WN4Zb79JZGQk23fvZcKdk3nowfsBqFq1Kg89PJUnnpoWkKzec57V4M0tSLTwnqfklvXYl3uUA98e42ThKeZ+sofUzs3c2hgDtapXAaB2jcoczvsFgLhGdVizxboU6Q8/neDYL/l0vKSeX/NmZmTQrFlzmjRtSuXKlRk6fASL09Pc2ixOT+OGUWMAuG7wENZ+vBpjDIvT0xg6fARVqlShcZMmNGvWnMyMDL/m3ZSVQeOmzWjcxMo7cPBwli1Od2uzbEk6w0eOAqDfwMF8uvZjjDGsWb2KhFatadW6LQDRdeoQHu7fn5JuzMqgqUve64YMY+niRe55Fy/i+husvAMGDeYTZ16AJelpNGrchLj4BL/mPC0rM4OmLsfDkGHDPRwPi4qOh0HXDWHtGut4qFGjBp27dKVK1aoByVom2uOt2GLq1iTnh5+LHtt/+AVbnZpubf4x83NGXBVP9qw/sfDxwdz92scAbP/6B/pd3pzwMKFRvdq0b3ExsRe6r+trubl2YmPPDGnYbLHY7faSbRpYbSIiIqhVuzZ5eXnY7SXXzc11X9fXDh/OxWaLLXocY7Nx+LD7a36bm4st1j3vj3l57Mv+ChFh6MBr6dk1mZefn+7XrACHXbJYeWM5fDjXrU1u8by1rLy//vorLz73DPc9MMXvOc9ksRPb4Mz+tdliOezpeCiWNy8vL2AZy0zEulaDN7cgCcqXayJSB1jtfFgPcAA/OB93MsYUnGPd7sC9xphUD8/9G3jOGLPLw3OTgX8aY06cZ3z37XpYZopNbzOsRxz/WbmTF+dncWl8fd7867V0vPVtZizfTlzDaD57dRTffHec9btyKXSc8mW8UrMBSLF3/rO28WJdXzufvI5CBxu++JyVa7+gWvXqDE7tTdv2Hbiye8+g5gXPbZ56/BFumzCZCy64wD/hPPAqbxD+v5+3EP9yLSiF1xiTB7QDEJFHgF+MMefdHTHG3OxpuYiEA5OB/wA+Lbz2Iz+79VJtF15A7o+/uLUZc01rBjw4H4ANuw9TtXI4dWtX54efTvDX19cWtVvz/PVk23/yZbwSbLZYcnIOnclvzyEmJqZkm0OHiI2NpbCwkOPHjhEdHY0ttuS69eu7r+trMTE27Pacose5djv16rm/Zn2bDXvOIWJsZ/JGRUcTY7NxeZcrqFPXmt2l1zV92bZls18Lb4wzy5m8OdSrV7/k35RzCNvpvMetvFlZGaR9uICH/34/x479RFhYGFWqVuXWP9/ht7zW/+sz+9duz6FeseMhxnnM2GLP5I2ODvF5CUP8jSGk3xZEpJuIbHHeNovI6Qp3gYjME5E9IjJLnG+/IrJWRJKc938RkakisgF4EIgB1ojIGl9mzPryW5rbomhUrzaVIsIY2i2OJV/sc2tz6Ief6d6uIQAtG0RTtXIEP/x0gmpVIqhe1fqyp2eHRhSeOsWeb/z7ES4pOZns7L0c2L+fgoIC5s6ZTUpqf7c2Kan9mTVzBgAL5s+jW4+eiAgpqf2ZO2c2+fn5HNi/n+zsvSR3KnkWhy+175jM/n3ZHDxg5f1w/hz6pLh/2OlzbSpz3psJQPqH8+narQciQo+rerNr53ZOnDhBYWEhn6/7L5fExfs1b4eOyexzybtg3gf0TennnjelH+/PsvKmLZzPlc68y1Z9wrbd+9i2ex+33XEnd997v1+LLkDHpGT2uRwP8z6Y4+F46Fd0PCxcMI9u3XuGeI839L9cC/XzeO8F7jDGfCYiFwCnzwVqDyQCucBnQBdgXbF1awA7jDFTAERkPNDDGHOk+IuIyK3ArQBUjSxTQMcpw12vrCb9icGEh4UxY8V2dh/M46HRXdj01bcsWb+P+99Yy2t39WbidR0xwC3TlwFwYWR10p8YwiljyD3yCzc9vaxMr/1HRERE8PyLr9Av5RocDgdjxo4nITGRqY9MoUPHJFL79Wfs+JsYP3YUiXHNiYqKZuas2QAkJCYyeOgw2rdJICIighdeetXvX1ZFRETw5PQXGTYwhVOnHFw/aixx8Yk89fgjtGvfkT4p/bhh9Hhuv2UsyW3jiIqK4p9vzwIgMiqK2yZMpne3yxERevXuQ+8+1/o97zPPvsjgAdficDi4YfRY4hMSeeKxh2nXIYlrU/oxasx4/nzzGDq0bklUVBRvznjPr5lKy/vsCy8zILUPDoeD0WPHkZCQyGOPTqFDhyRS+vVnzLibuHncaFrHtyAqOpoZM98vWj/+kib8fPw4BQUFpKensWjJCuID9MXgOYX0GwOIpzGegAY4x1CDiNwPDAJmAQuMMTnOMd4HjTFXO9v8H/CZMeY/IrIWa/w3S0QKgSrGGIez3QEgyVPhdRVWq4EpT7MMH9VZhv1KZxn2vxpVwjYaY5J8tb2wyIamSte/etX29yUTffra3gqp/0MicofL0EKMMeYp4GagGrBeROKcTfNdVnPguef+++miq5T6X6JDDWVijHkVePX0YxFpZozZDmwXkcuBOOCPfvv0M1ATOGePVylVAYT41D8h1eP1YLKI7BCRrcBvwPkMgv4TWObrL9eUUiEoxH9AEfQerzHmkXM8N9HD4rXO2+k2E1zud3e573YypDHmZeDlPxxUKVU+iF4IXSmlAi/Ez2rQwquUqnBC+zxjLbxKqQrGmvlHC69SSgWOCBLi519r4VVKVTja41VKqQDTwquUUgEW6oU3tE92U0qpspIy3LzZnEgfEflSRLKd148p/nxDEVnjvILiNhEp9UpMWniVUhWKIIh4dyt1W9a1vF8F+gIJwPUiUvzya38HPjDGtAdGAK+Vtl0dalBKVThhYT7rU3YCso0xXwOIyGxgAOA6y40Bajnv18a6XO05aeFVSlU4PhzjtQGHXB7nAJcWa/MIsFJEJmJdB7xXaRvVoQalVMVStjHeuiKS5XK71cPWiit+EfPrgXeMMbHAtcBMkXNfLEJ7vEqpCqcMPd4jpVwIPQdo4PI4lpJDCTcBfQCMMV+ISFWgLvD92TaqPV6lVIXiyy/XgEyghYg0EZHKWF+eLSrW5hvgKgARiQeqcmbWdI+0x6uUqnB8NcZrjCkUkQnACiAceMsYs1NEpgJZxphFwD3Av0TkLqxhiLGmlDnVtPAW067FxXy25J5gx/BaVPKE0huFkCMbytclkUP7NHzPwkL8OgV+J/j0Wg3GmKXA0mLLprjc34U14a7XtPAqpSqcUP/lmhZepVSFo4VXKaUC6PSXa6FMC69SquIJ7bqrhVcpVcGIDjUopVTA+fBaDX6hhVcpVfGEdodXC69SquLRoQallAqgMvwcOGi08CqlKhwtvEopFWBaeJVSKsB8ea0Gf9DCq5SqWPQ8XqWUCiwBQrzuauFVSlU0oX9WQ2j/vKOcWLliOW0T42gV34LpzzxV4vn8/HxGjRxBq/gWXNnlMg4eOABAXl4efa7uyYVRNblrUuCuq3t153i2LnyIHWkPc++4q0s837B+FEtfn0jGnL+x4l+TsF0UCcCVSS1YP/v+otvR9c/Tr3sbv+ddtWI57VvF0Sa+Bc9O87x/R98wgjbxLeje1X3/9u3dk4uja3J3APfvyhXLadcqjtbxLZh+jryt41vQzUPei4KQt01iSxLjmjPtLMfvjSOHkxjXnCs6X1qUF2Da00+SGNecNoktWbVyRcAyl0bEu1uwaOE9Tw6Hg7smTeDD9KVs2rqTuXNms3vXLrc277z9JpFRkezYvZeJd07m7w/cD0DVqlWZ8shUnnh6WsDyhoUJL9w/jAETXqP94McZ2qcjcU3rubV58q5BzFqSQafhT/LEP5cxdWJ/AP6btZfLRjzFZSOeou+tL3Hi9wI+Wr/br3kdDgd3T5rAgkVLyTq9f3e7798Zb79JZGQk23bv5Y47J/PQg2f270MPT+UfTwVu/57Ou3DRUjaWknf77r1M8JD3iQDnnXznHaSlL2Pztl3Mnf1+yeP3rTeJioxi555sJk66iwcfuA+A3bt2MXfObDZt3cmixcuZNPF2HA5HwLKfiw+n/vELLbznKSszg2bNmtOkaVMqV67MkGHDWZye5tZmSfoibhw1BoBBg4ewds1qjDHUqFGDzl26UrVq1YDlTW7VmH2HjnDAnsfJQgdzV2witVivNa5pfdZu+BKATzK/IrV76xLbGdSrPSs/28Vvv5/0a96szAyaFtu/Szzs3xtO79/rgrt/PeUtfjwsLiVvlQDmzcxwP36HDh/hIW9aUd7rBg9h7cdW3sXpaQwdPoIqVarQuEkTmjVrTmZGRsCyn5WXvV3t8ZZjuXY7ttjYosc2Wyy5uXYPbayJSiMiIqhVuzZ5eXkBzXlazEW1yfnuaNFj+3dHsV1Y263N9q/sDLyqHQADeral1gXViK5dw63N0Gs68MHyjX7Pm5trJ7ZBsf1rt5ds47J/a9cK3v71lPdwKXlrBTtv7JlJdG22WOye8jYoefza7SXXLX7sB4MA4eHi1S1Y/Fp4RaSOiGxx3r4VEbvL48r+fO1A8TSnXfGPMN60CRTxcPWQ4un+9vxCrujYnC/ev48rOjbH/t1RCl0+QtarW4vEFjGs+mIX/lbe9q9XWcpZ3rO2CaG/o7hQH2rw61kNxpg8oB2AiDwC/GKMme7aRqy/Xowxp/yZxeX1Iowxhb7ani02FntOTtFjuz2H+vVjPLQ5RGxsLIWFhRw/dozo6GhfRSgT+/c/EXtx1JlsF0eR+8MxtzaHfzjGiHv/DUCNapUZeFU7jv/ye9Hzg6/uwKKPt1FY6P//ZTZbLDmHiu3fmJiSbXIOYXPu32PHg7d/PeWtVyxvTLG8x4OdN+dQ0WO7PYcYT/v3UMnj1xZbct3ix35QBHkYwRtBGWoQkeYiskNEXgc2AfVF5EYR2e5c/oSzXYSI/OSy3ggR+bfL/R0islVE1ri0f05EMkRkm4jc7FzeS0Q+EpHZwGZf/i0dk5LJzt7Lgf37KSgoYN4Hc0hJ7e/W5trUfvxn5gwAFs6fR7fuPYP2bpu18yDNG15Io5g6VIoIZ+g1HViydptbmzqRNYry/WX8NcxIW+/2/LA+HflgeVZA8nZMSmZfsf17rYf9O+v0/l0Q3P3rKW/x4yElhPImJbsfv3PnzPaQt39R3gXz59Gth5U3JbU/c+fMJj8/nwP795OdvZfkTp2C8We4sc7j/R/u8ZYiARhnjPmziMQCjwNJwDHgIxFJBZafY/2Hge7GmO9EJNK57Fbge2NMJxGpAqwXkZXO5y4DEowx3xTfkIjc6lyXBg0blumPiIiI4LkXXqZ/Sh8cpxyMHjOOhMREpj4yhQ4dk0jt15+x427iprGjaRXfgqioaN79z/tF68e1aMLPx49TUFBA+qI00pesID4hoUwZysLhOMVdT39A+mt3EB4mzEhbz+6vv+Wh21LYtOsblnyynSuTWjB1Yn+MgXWbspn85AdF6zesH01svSg+3Zjtt4yuIiIiePaFlxmY2geHw8GoseNISEjksUen0KFDEin9+jNm3E3cPG40beJbEBUdzTszz+zfhEvO7N/F6WmkLVlBfLz/9u/pvAOceUefI29rZ94ZLnnjXfKmp6exKAB5n3/xFfqlXIPD4WDM2PElj9/xNzF+7CgS45oTFRXNzFmzAUhITGTw0GG0b5NAREQEL7z0KuHh4X7L6r3QP49XPI3f+OWFXIYaRKQ5sMwY08L53GAgxRgz3vn4T0Az4AHgiDEm0rl8BNDLGHOzs+fbAJgLLDDG/CgiHwLxwG/Ol60N3Iz1JnifMabkSavFdOiYZD5bn+mzv9vfojtNDHaEMjmy4eVgRyiT0P7n61lYiF+noLhqlWSjMSbJV9urHtPSXHLra1613fpoL5++treC2eP91eX+2Y6UU8Wecz3P5hbgUiAV2CoibZxtbzfGrHbdiIj0KvZ6SqmKSkL/zSdUTidbD/RwngURAYwAPnF+4XZURFqISBgwyGWdpsaY9cBDwFHABqwAbnduAxFpKSLVAvqXKKWCSsd4vWSMyRGRKcBarP2WboxZ4nz6Pqyx3m+AXUAV5/LnRaSJs/1KY8wOEdkNNAS2OHfq98CAgP0hSqmQEOJDvIErvMaYR1zuZ+M8zcxl2Uxgpof15gBzPCzv72GZA7jfeXP1kfOmlPofEOpfroVEj1cppXwpxOuuFl6lVAWjF0JXSqnAEiTkz2rQwquUqnBCvMOrhVcpVfHoUINSSgVSObhIjhZepVSFcvoHFKFMC69SqsLRwquUUgEW6mc1hMq1GpRSyjd8POeaiPQRkS9FJFtEiv8q9nSbYSKyS0R2ish7pW1Te7xKqQpFfHg9XhEJB14FrgZygEwRWWSM2eXSpgXwN6CLMeaoiFxU2na1x6uUqnB82OPtBGQbY742xhQAsyl54a1bgFeNMUcBjDHfl7ZRLbxKqQonTMSrG1BXRLJcbrcW25QNOOTyOMe5zNUlwCUi8pmIrBeRPqXl06EGpVSFU4aRhiOlzEDhaUvFp+2JAFoA3YFY4FMRaWWM+an4iq4rKKVUhSEC4b47qyEHa4qx02KBXA9t1htjTgL7ReRLrEJ81jnEzlp4RaTWudIYY46Xlri8CtA0dD5xNPOVYEcok5jxpX7hG1Jy/n19sCOU2d5vfwl2hKDz4Xm8mUAL56QLdqzZcUYWa/MhcD3wjojUxRp6+PpcGz1Xj3cnVpfa9S84/dhgzfSglFIhx1d11xhTKCITsKYVCwfeMsbsFJGpQJYxZpHzud4isgtwAH8xxuSda7tnLbzGmAZne04ppUKVYJ1S5ivGmKXA0mLLprjcN8DdzptXvDqrQURGiMgDzvuxItLR2xdQSqlACxPvbkHLV1oDEXkF6AGMci46Abzuz1BKKfWHeTnDcKjPMtzZGNNBRDYDGGN+FJHKfs6llFJ/WIhfI8erwntSRMJwnrsmInWAU35NpZRSf5Dg09PJ/MKbMd5XgfnAhSLyKLAOeNqvqZRS6jyU+6EGY8y7IrIR6OVcNNQYs8O/sZRS6o8py5XHgsXbX66FAyexhhv0+g5KqZAWFuKV15uzGh4E3gdisH4u956I/M3fwZRS6o8SL2/B4k2P90agozHmBICI/APYCDzpz2BKKfVHVYSpfw4WaxdBKb9DVkqpYBGRkD+r4VwXyXkea0z3BLBTRFY4H/fGOrNBKaVCUoh3eM/Z4z195sJOYInL8vX+i6OUUuev3A41GGPeDGQQpZTyBSG412HwhjdnNTQTkdkisk1Evjp9C0S48mLliuW0axVH6/gWTJ/2VInn8/PzGX3DCFrHt6Bb18s4eOAAAHl5efTt3ZOLomty96QJAc3bJrEliXHNmfaM57w3jhxOYlxzruh8aVFegGlPP0liXHPaJLZk1coVAcl7Vev6bHg6laxp/ZiUmlDieVud6qTdfxVrH+vDp4/3pVebmKLnJqcmkDWtHxueTqVn6/oByVvejod1a1bRr1t7Urq25c1Xny3xfNb6dQzr25X2jSNZueRDt+ee+8ffGXRVMgN6dOSpKX/BhMjFrEP9BxTenJP7DvA21htJX+ADrAnfFOBwOLh70gQWLlrKxq07mTtnNrt373JrM+PtN4mMjGT77r1MuHMyDz1ozRBdtWpVHnp4Kk88NS2geSffeQdp6cvYvG0Xc2e/z+5d7nnfeetNoiKj2Lknm4mT7uLBB+4DYPeuXcydM5tNW3eyaPFyJk28HYfD4de8YSI8MzqJYdPXcPn9Sxh8WSNaxrhfo//e/q34MOMg3R9azs2vfcb0MdZMLi1janHdZY3o/LclDJ22hmmjk/x+fmd5PB6e+Ps9/N+7C/jw40yWpc1j31d73NrUtzXg8edep+/AYW7Lt2StZ0vWeuatXM+CjzLYsXUjWetD4+ufUD+dzJvCW90YswLAGLPPGPN3rKuVKSArM4OmzZrTpGlTKleuzJBhw1mcnubWZnH6Im4YNQaAQdcNYe2a1RhjqFGjBp27dKVK1aoBy5uZkUEzl7xDh4/wkDetKO91g4ew9mMr7+L0NIYOH0GVKlVo3KQJzZo1JzMjw695Ozarw/7vf+HgD79y0nGKBesP0rdDrFsbYww1q1UCoFb1ynz7028A9O0Qy4L1BykoPMU3R35l//e/0LFZHb/mLW/Hw44tWTRs3JTYRk2oVLkyffoPZs3KxW5tbA0acUl8qxJvWiJCfn4+JwsKKCjIp/BkIXXqXhiw7Gdzeuofb27B4k3hzRerT75PRP4sIv2AUueN/1+Rm2sntsGZQmCzxXLYbi/ZJta6rnxERAS1atUmL++cF6j3G9csYOW1e8rbwCVvbSuv3V5y3dxc93V9rX5UNex5v57J9uMJ6kdVd2vz9MLtDOvchB0vDGTOPd25b2aWc93q2H88UWzdan7NW96Oh+++PczFMWcmzb24vo3vvz3s1bptO15K8uVXcFVSC67q2ILO3a6iaYs4f0Utk4ow1HAXcAFwJ9AFaw758aWtJCIOEdkiIjtEZK6IVC+l/TsiMsR5f62InGvmz5DhaUyrxP9Qb9oEiDd5z9omCH+H5yle3XMMvrwx73/6Na0mf8jwZ9fy+p86n/X3+v4egixvx8P5ZPlm/z72Z3/Jqow9fJT5JRmffxI6Qw3i3S1YSi28xpgNxpifjTHfGGNGGWP6G2M+82Lbvxlj2hljWgEFwJ/PO62PiEi4r7Zls8WScyin6LHdnkO9mBi3NjG2WHJyDgFQWFjI8ePHiI6O9lWEMrG5ZAErb0yxvNbf5JL3mJXXFlty3fr13df1tdyjv2GrU6PocUx0db49+ptbmxuvbMqHGd8AkJl9hCqVwqlzQRVyfzyBLbq6+7o/ua/ra+XteLi4fgzfuXxq+e6wnQsvrufVuqtXpNOmfSeq17iA6jUuoGuP3mzbfNaJdQNGEMLEu1uwnLXwishCEVlwtlsZX+dToLmINBaRoiubici9IvLIuVYUketFZLuz5/y0c9ltIvKMS5uxIvKy8/6NIpLh7G2/cbrIisgvIjJVRDYAl5cx/1l1TEpmX/ZeDuzfT0FBAfM+mENKan+3Nimp/Zg1cwYACxfMo1v3nkHr4SQlJ5PtknfunNke8vYvyrtg/jy69bDypqT2Z+6c2eTn53Ng/36ys/eS3KmTX/Nu+jqPphfXpGHdGlQKD+O6yxqxfLP7R/ecvBNcmXAxAJfE1KJKpTCO/JzP8s12rrusEZUjwmhYtwZNL67Jxn3+/Uhf3o6HxLYdOXhgHznfHOBkQQHLF82n+9UpXq1bP6YBWRvWUVhYyMmTJ8lav46mzVv6ObEXvOztBrPHe64fUPhk3nARicA6G2L5H1g3Buvavx2Bo8BKERkIzAO+AP7qbDoc+IeIxDvvdzHGnBSR14AbgHeBGsAO10nqXF7nVuBWgAYNyzZ5ckREBM++8DIDUvvgcDgYPXYcCQmJPPboFDp0SCKlX3/GjLuJm8eNpnV8C6Kio5kx8/2i9eMvacLPx49TUFBAenoai5asID6+5ClTvhIREcHzL75Cv5RrcDgcjBk7noTERKY+MoUOHZNI7defseNvYvzYUSTGNScqKpqZs6yTWBISExk8dBjt2yQQERHBCy+9Sni4zz48eOQ4Zfjru1nM+2sPwkWY9d+v2WM/xt+ua83m/T+yfLOdh97fxAvjL+W2PnEYAxP+Zf3GZ4/9GB9u+IYvnkyh8JThr+9mcsrPYw3l8Xh44LHp3HbjQByOUwwcPoo+9c36AAAgAElEQVTmLeN5dfrjJLRpT4/eKezYspHJt4zk+LGf+OSjZfzfc/9g4epMrk4ZSMbnnzD46ksREbp060X3q6/1W9ayCPUfUIi/zrsTEQew3fnwU+AerCucLXYOPyAi9wIXGGMeEZF3nM/NE5G1wL2ADRhsjBntbH8TkGiMuVtEVgJTgL1AJtAMuAN4APje+brVgPed2y8Eqhhjznn+U4eOSWbdF8H/uOStsFA/U7yYmPHvBTtCmeT8+/pgRyizfd//WnqjENKmQc2NxhiffadzcfNWZvj0eV61fXlQvE9f21veXo/3j/jNGNPOdYGz+LkOb5R23sy5qsocYBiwB1hojDHOsy9mGGM8Xbby99KKrlKqYgj1/kigL2r+HXCRiNQRkSpAaintNwDdRKSuc6z2euAT53MLgIHOZXOcy1YDQ0TkIgARiRaRRr7+I5RSoS3Up3f3uscrIlWMMfnn82LOcdepWAV1P1Zv9VztDzsvur4Gq/e71BiT5nzuqIjsAhKMMRnOZbtE5O9YY8FhWLNm3IF1aUul1P8A64uz0O7yllp4RaQT8CZQG2goIm2Bm40xE8+1njHmgrMsfwl4ycPysS73u7vcfw/wODBojCnRYzbGzOFMD7jUPEqpiqciDDW8hDUkkAdgjNmK/mRYKRXCyvPpZKeFGWMOFuu665dUSqmQJEBEeR9qAA45hxuM8wuuiYBeFlIpFbJCvO56VXhvwxpuaIh1VsJHzmVKKRVyJMg/B/ZGqYXXGPM9MCIAWZRSyidCvO56dVbDv4ASP28zxtzql0RKKXWeQv2sBm+GGj5yuV8VGAQcOktbpZQKKmvOtdCuvN4MNbidEysiM4FVfkuklFLnQyA80L/JLaM/cq2GJoD+DFcpFbIkqDOqlc6bMd6jnBnjDQN+BO73ZyillPqjyv307s6rfbUFLnTeoowxTY0xHwQinFJK/RG+vEiOiPQRkS9FJFtEztrpFJEhImK8mbbsnIXXWBfrXWiMcThvfp6xSimlzp+vJrt0/mjsVazJHBKA60WkxJXpRaQm1ryUG7zJ580QdIaIdPBmY0opFWynhxp81OPtBGQbY742xhQAs4EBHto9BjwD/O7NRs8159rp8d+uWMX3SxHZJCKbRWSTV5GVUirQyjbnWl0RyXK5Ff99gg3302dznMvOvJxIe6CBMWaxtxHP9eVaBtAB62LjSilVLggQ4f23a0dKmfrH04aKhlyd1/1+Hhjr7QvCuQuvABhj9pVlg0opFWw+/P1EDtDA5XEskOvyuCbQCljrHDOuBywSkf7GmKyzbfRchfdCEbn7bE8aY57zJnV5c8oYfisoP1e9rFHVn9Pm+V55mzyyTp8ngx2hzL5b+r9+tqcQ5rvzeDOBFiLSBLBjXbdm5OknjTHHgLpFr+ycqPdcRRfOXXjDgQs494STSikVUgTf9XiNMYUiMgFYgVUT3zLG7HROYZZljFn0R7Z7rsJ72Bgz9Y9sVCmlgsbHE1kaY5YCS4stm3KWtt292WapY7xKKVXelOeL5FwVsBRKKeUjAoSH+G+Gz1p4jTE/BjKIUkr5Soh3eP/Q1cmUUipkCd79JDeYtPAqpSoWwavrMASTFl6lVIUT2mVXC69SqoKpEFP/KKVUeRPiJzVo4VVKVTTeXWs3mLTwKqUqFD2rQSmlgkB7vEopFWChXXZDv0deLqxetYJL2yeS3DaOF599psTz+fn53DRmJMlt4+jdozPfHDxQ9NzOHdvo07MrXZLbcsWl7fj9d69mDjkvK1csp01iSxLjmjPtmac85r1x5HAS45pzRedLOXjgTN5pTz9JYlxz2iS2ZNXKFX7Pejpvu1ZxtI5vwfRpnvOOvmEEreNb0K3rZUV58/Ly6Nu7JxdF1+TuSRMCkhXg6uSmbJ3xJ3bM/DP3Xn95iecbXlyLpdNHkvGvm1nx3A3Y6tYsei7tqeEcXnQ38/8xNGB5P1q5nI5t4mmXeAnPTXu6xPP5+fmMvXEE7RIvoecVl3PQefxuzMyg66Ud6HppB7p0ak962sKAZT4n8d2ca/6ihfc8ORwO7rvnTuYsSOezzG0smDebL/fscmsz6923iIyMJHPrHv58xyQenfIAAIWFhdx28ximv/gqn2VuJW3paipVquT3vJPvvIO09GVs3raLubPfZ/cu97zvvPUmUZFR7NyTzcRJd/HgA/cBsHvXLubOmc2mrTtZtHg5kybejsPh32sXOxwO7p40gYWLlrJx607mzpnN7t3ueWe8/SaRkZFs372XCXdO5qEHrevRVq1alYcensoTT03za0ZXYWHCC5OuYcD9c2g/7p8M7ZlAXKO6bm2e/PNVzFq5nU63/JsnZq5j6i3di557fs4GbnryD11p8A9xOBzcM3ki89KWkLF5B/PnzmZPsf377jtvERkVxZadX3H7xEk87Ny/8YmtWPtZBus2bGJ+2lImT7yNwsLCgGU/GwHCRby6BYsW3vO0KSuDJk2b0bhJUypXrsygwcNZtjjdrc2yJemMGDkKgP4DB/Pp2o8xxrBm9SoSWrWmVeu2AETXqUN4eLhf82ZmZNCsWXOaNLXyDh0+gsXpaW5tFqenccOoMQBcN3gIaz9ejTGGxelpDB0+gipVqtC4SROaNWtOZkaGX/NmZWbQ1CXvkGHDPeRdVJR30HVDWLvGylujRg06d+lKlapV/ZrRVXJcDPvsRzlw+CdOFp5i7se7SO3cwq1NXKO6rN10AIBPNh8ktfMlRc+t3XyAn08UBCzvxswMmjZrRhPn8Xvd0OEsWexe+JcuTmPkDaMBGHjdED5xHr/Vq1cnIsIarfw9//eQGlcVL2/BooX3PB0+nEuMLbbocYzNxuHDdvc2ubnYYq3ZQyIiIqhVuzY/5uWxL/srRIShA6+lR9dkXnp+ut/z5ubaiY09M5OJzRaL3W4v2aaBe968vDzs9pLr5ua6r+uXvA3O7F+bLZbDnvK67t9aVt5giKlbk5zvjxc9th/5GduFNd3abN/3PQOvjANgwBUtqVWjCtG1qgU052m5ufaiYxPAZrOV2L8ljt9a1vELkJWxgUs7tKZzUluef+m1okIcbGWY7DIoQqbwiohDRLaIyE4R2SoidzsnkgtpxpgSy4q/85+tTWGhgw1ffM7r/36XJSs/YWn6h/x37cd+y3quLF618WJdX/MmbzBynY2nly0e72+vr+aKtg354o3xXNGmIfYfjlPoOBWYgCWyncfxACR1upQNm7azZt0Gnpv2dEC+oyiNdTqZeHULllAqbL8ZY9oZYxKBq4FrgYeLN3KZdj4kxMTYyLXnFD3OtdupVy/GvY3Nhj3HmiG6sLCQ48eOERUdTYzNRucuV1Cnbl2qV69Or2v6snXLZr/mtdliyck5M1u13Z5DTExMyTaH3PNGR0djiy25bv367uv6Je+hM/vXbs+hXkzx/XsmV2FhIcePW3mDwf7Dz8ReVKvosa1uTXKP/OzW5nDeL4x4eD6X/+ktHn5zLQDHf80PZMwiNlts0bEJYLfbPezfYsfvcev4ddUyLp4aNWqwa+cO/4f2gvZ4/wBjzPfArcAEsYwVkbkikg6sBBCRv4hIpohsE5FHnctqiMgSZ495h4gMdy5/SkR2Odv69PN8+47JfL0vm4MH9lNQUMDC+XPok5Lq1qbPtanMfm8mAIs+nM8V3XogIvS8qjc7d27nxIkTFBYW8vm6/9IyLt6X8UpISk4mO3svB/ZbeefOmU1Kan+3Nimp/Zk1cwYAC+bPo1uPnogIKan9mTtnNvn5+RzYv5/s7L0kd+rk17wdk5LZ55J33gdzPOTtV5R34YJ5dOveM2g93qw9uTS3RdGoXm0qRYQxtGcCS77Y69amTq1qRf/o/zKyMzOWbQtCUkuHpGT2ZWdzwHn8Lpg7h2tT+rm1uTalP+/NeheADxfM40rn8XvgwP6iL9O+OXiQvV99SaNGjQP9J3ggXv8XLCHVe3RljPnaOdRwkXPR5UAbY8yPItIbaAF0wvpksUhErgQuBHKNMSkAIlJbRKKBQUCcMcaISGTx1xKRW7EKPbENGpYpZ0REBE9Nf5GhA1M4dcrByFFjiYtP5MnHH6Fd+470TenHDaPHc/stY0luG0dkVBT/ensWAJFRUdw2YTJXd7scEaFX7z707nNtmfdVWfM+/+Ir9Eu5BofDwZix40lITGTqI1Po0DGJ1H79GTv+JsaPHUViXHOioqKZOWs2AAmJiQweOoz2bRKIiIjghZde9fuXgRERETz7wssMSO2Dw+Fg9NhxJCQk8tijU+jQIYmUfv0ZM+4mbh43mtbxLYiKjmbGzPeL1o+/pAk/Hz9OQUEB6elpLFqygvj4BL/ldZwy3PXyStKfHkF4eBgzlm1l94EjPDT2SjZ9dZgln+/lynaNmHpzd4wxrNt2iMkvnTkt76MXRnFJwzpcUK0S2XMm8OdpS/goa7/f8kZERDD9+Ze4rl9fHA4HN44ZR3xCIv+Y+jDtO3Tk2tT+jBo7nlvHj6Zd4iVERUXz1sz3AFj/+Tqen/4MlSpVQsLCePbFV6hTt24pr+h/p89qCGXiafwmGETkF2PMBcWW/QS0BPoC3Ywx45zLpwNDgJ+cTS8AngQ+xZoN9ANgsTHmU+fQxEYgC1jiXH7Wr43bdehoVv93g0//Nn8qb9O7nzoVGsebt3R6d/+rXS18ozEmyVfbu6RVO/PyB6u8atsn8SKfvra3QvZfrYg0BRzA985Fv7o+DTxpjHnDw3odscaHnxSRlcaYqSLSCWsOuRHABKCnX8MrpYIqxDu8oVl4ReRC4HXgFefwQPEmK4DHRGSWMeYXEbEBJ7H+nh+NMf8RkV+AsSJyAVDdGLNURNYD2QH8U5RSQRDM8VtvhFLhrSYiW4BKQCEwE3jOU0NjzEoRiQe+cBblX4AbgebANBE5hVWIbwNqAmkiUhWrp3yXv/8QpVTwWBdCD3aKcwuZwmuMOeu3NMaYd4B3ii17EXixWNN9WL3h4vz71btSKqRoj1cppQJMx3iVUiqAysPpZFp4lVIVTHB/HOENLbxKqYolyD8H9oYWXqVUhRPidVcLr1KqYrFOJwvt0quFVylV4YR22dXCq5SqgEJpNgxPtPAqpSqcEK+7WniVUhVPiNddLbxKqQooxCuvFl6lVIVizSAc2pU3JKf+UUqpP8zL+da8HQcWkT4i8qWIZItIiavMOyfmPT212GoRaVTaNrXwKqUqHF8VXhEJB17FmgUnAbheRIrPHbUZSDLGtAHmAc+Utl0tvEqpCsank112ArKNMV87pwybDQxwbWCMWWOMOeF8uB6ILW2jWniVUhVOGXq8dUUky+V2a7FN2YBDLo9znMvO5iZgWWn59Mu1YsJEqFbZvzPn/i/b/8OvpTcKITmL/hrsCGUWN/nDYEcIKqFMJzUcKWWyS0+b8jhjq4jcCCQB3Up7US28SqmKx3cnNeQADVwexwK5JV5OpBfwINZs6PmlbVSHGpRSFY4Px3gzgRYi0kREKmPNVL7I7bVE2gNvAP2NMd972EYJ2uNVSlU4vprs0hhTKCITsOZyDAfeMsbsFJGpQJYxZhEwDbgAmOu8RsQ3xpj+59quFl6lVMVSxkHe0hhjlgJLiy2b4nK/V1m3qYVXKVXhhPov17TwKqUqFEGvTqaUUgEX4nVXC69SqgIK8cqrhVcpVeHonGtKKRVgoV12tfAqpSqiEK+8WniVUhVKebgQuhZepVTFUoaLnAeLFl6lVIUT4nVXL5LjCytXLKddqzhax7dg+rSnSjyfn5/P6BtG0Dq+Bd26XsbBAwcAyMvLo2/vnlwUXZO7J00IaN42iS1JjGvOtGc8571x5HAS45pzRedLi/ICTHv6SRLjmtMmsSWrVq4ISN51a1aRemV7+nZpy79febbE81nr1zG0T1faNopk5eIzl0TM+Oy/DO7duejWoVldVi9P93ve1atWcGn7RJLbxvHisyUnI8jPz+emMSNJbhtH7x6d+ebggaLndu7YRp+eXemS3JYrLm3H77//7ve83RMu5tNHruazqb2ZcM0lJZ5/ZGhrVj3Yk1UP9uTTR69m93OpAHS+pG7R8lUP9uTrlwfQp219v+ctnSDi3S1YtMd7nhwOB3dPmkD60pXYYmO5onMnUlL7Ex9/ZnaQGW+/SWRkJNt372XuB7N56MH7eXfWbKpWrcpDD09l184d7Nq5I2B5J995B0uWrcIWG0vXy5JJTe1PfMKZvO+89SZRkVHs3JPNB3Nm8+AD9/Gf9+awe9cu5s6ZzaatOzmcm8u1fXqxfddXhIf77/rFDoeDx/9+D/96L4169W0MT+lGj94pNLskrqhNfVsDHn/udd554yW3dTt1uZL5Kz8H4NjRH+nbtR2du13lt6yn8953z53MS1tGjC2Wq7tdRp+UVFrGndm/s959i8jISDK37mHBvDk8OuUB3pzxHoWFhdx28xhe+9c7tGrdlh/z8qhUqZJf84YJPHF9W0a8uI7DR39j6d96sGLbYfYe/rmozSNztxfdH9+9Ka0aRALw+VdHuPofHwMQWb0Snz12DZ/s8uriXH4X6kMN2uM9T1mZGTRt1pwmTZtSuXJlhgwbzuL0NLc2i9MXccOoMQAMum4Ia9esxhhDjRo16NylK1WqVg1Y3syMDJq55B06fISHvGlFea8bPIS1H1t5F6enMXT4CKpUqULjJk1o1qw5mRkZfs27fUsWDRs3pUGjJlSqXJm+Awbz8crFbm1sDRrRMqEVYee4JNXKJR9yRY+rqVatul/zbsrKoEnTZjRuYu3fQYOHs2yxey972ZJ0RowcBUD/gYP5dO3HGGNYs3oVCa1a06p1WwCi69Tx65saQPvG0Rz4/le+OXKCkw5DWmYO17Q5e691YHIDPszKKbE8pYONNTu/5beTDn/G9YqU4RYsWnjPU26undgGZ6ZYstliOWy3l2wTa11LOSIiglq1apOXlxfQnJ6ygJXX7ilvA5e8ta28dnvJdXNz3df1te8PH6Ze/TMzrVxcz8b3hw+XeTvLFs2n78Ahvozm0eHDucTYzhwPMTYbhw+776PDubnYYt337495eezL/goRYejAa+nRNZmXnp/u97z1oqqSe/S3M9l++o36UdU8trVFV6NB3Rqs21OyVzsgKZYPM0sW5KAJ8cob8kMNIlIPeAFIBvKBA8BkY8xXZdhGJDDSGPOar/MZU3IWkBJjR960CRBv8p61TRD+DuNhlpWyvuYP333L3j076dKtzFfvK7Pz2b+FhQ42fPE5q9Z+QbXq1bkutTft2nfgyu49/ZbX02lXHuIBMDCpAUs22TlV7PmLalUl3labtTu/80PCPybUTycL6R6vWEfsQmCtMaaZMSYBeAC4uIybigRu93U+sHp9OYfOvNPb7TnUi4lxaxNjiyUnx5ovr7CwkOPHjxEdHe2POKWyuWQBK29MsbzW3+SS95iV1xZbct369d3X9bWL68fwrUuP8btv7VxYr16ZtrE8fQFX9enn9/FSgJgYG7n2M8dDrt1OvXrFjwcb9hz3/RsVHU2MzUbnLldQp25dqlevTq9r+rJ1y2a/5j189DdiXHq49SOr8e1Pv3lsa/VqD5VY3i/JxrItuRQWr8hB5Kvp3f0lpAsv0AM4aYx5/fQCY8wWYJ2ITBORHSKyXUSGA4jIBSKyWkQ2OZefnob5KaCZiGwRkWm+DNgxKZl92Xs5sH8/BQUFzPtgDimp7hefT0ntx6yZMwBYuGAe3br3DFqPNyk5mWyXvHPnzPaQt39R3gXz59Gth5U3JbU/c+fMJj8/nwP795OdvZfkTp38mrdV2458s38fOd8c4GRBAcvS5tPj6pQybWNZ2lyuHTDUTwndte+YzNf7sjl4wNq/C+fPoU9KqlubPtemMvu9mQAs+nA+V3TrgYjQ86re7Ny5nRMnTlBYWMjn6/5Ly7h4v+bdcvAoTS66gAZ1qlMpXBiQHMvKbSWHcppdfAG1a1Qi6+sfSzw3MKmBx4IcTCE+0hDyQw2tgI0ell8HtAPaAnWBTBH5L/ADMMgYc1xE6gLrRWQRcD/QyhjTztOLOKd0vhWgQcOGZQoYERHBsy+8zIDUPjgcDkaPHUdCQiKPPTqFDh2SSOnXnzHjbuLmcaNpHd+CqOhoZsx8v2j9+Eua8PPx4xQUFJCensaiJSvczojwtYiICJ5/8RX6pVyDw+FgzNjxJCQmMvWRKXTomERqv/6MHX8T48eOIjGuOVFR0cycNRuAhMREBg8dRvs2CURERPDCS6/6/cufiIgIHnhsOn+6YSCOU6cYNHwUzVvG88q0x0ls254evVPYvmUjk28eyfFjP7F21TJefe4fpH2cCYD90EG+zbWTdHlXv+Z0zfvU9BcZOjCFU6ccjBw1lrj4RJ58/BHate9I35R+3DB6PLffMpbktnFERkXxr7dnARAZFcVtEyZzdbfLERF69e5D7z7X+jWv45ThwTlbeO/OLoSHCbM/P8hXh3/mL/3i2Xrwp6IiPDC5AWkexnBj61QnJroaX+w94tecZSLBG8rzlngabwoVInIn0MQYc1ex5c8D240xbzkfzwTmYs1n/zxwJXAKaAk0AaoCi40xrUp7zQ4dk8y6LzJ9+nf407m+yQ9F+777JdgRyqRe7cCdceIrre9dVHqjEHL4jcEbS5livUzatu9olq75wqu2sVFVfPra3gr1Hu9OwNNX0WerNjcAFwIdjTEnReQAVtFVSv0PCfXuSKiP8X4MVBGRW04vEJFk4CgwXETCReRCrB5uBlAb+N5ZdHsAjZyr/QzUDGx0pVSwhPqXayHd4zXGGBEZBLwgIvcDv+M8nQxrOuWtgAH+aoz5VkRmAekikgVsAfY4t5MnIp+JyA5gmTHmL0H4c5RSARLqp5OFdOEFMMbkAsM8PPUX58217RHg8rNsZ6Tv0ymlQlJo193QL7xKKVUWItY1KEKZFl6lVIWjQw1KKRVooV13tfAqpSqeEK+7WniVUhVPiP9wTQuvUqqiER3jVUqpQBK0x6uUUgGnhVcppQJMhxqUUiqQgnwdBm9o4VVKVSjBvsi5N7TwKqUqnhCvvFp4lVIVTliIjzWE+vV4lVKqzHw555qI9BGRL0Uk23l52uLPVxGROc7nN4hI49K2qYVXKVXx+Kjyikg48CrQF0gArheR4pMi3gQcNcY0x5p67OnStquFVylV4YiX/3mhE5BtjPnaGFMAzAYGFGszAJjhvD8PuEpKmW1Tx3iL2bxp45EaVcIO+mHTdYEQmorVK+Uts+b1L3/lbVR6E+9t3rRxRfXKUtfL5lWdM9ac9k9jzD9dHtsA17nrc4BLi22jqI0xplBEjgF1OMe+0sJbjDHmQn9sV0SygjGb6fkob5k1r3+Vl7zGmD4+3Jynnmvxqdm9aeNGhxqUUurscoAGLo9jgdyztRGRCKxJd38810a18Cql1NllAi1EpImIVAZGAIuKtVkEjHHeHwJ8bIw5Z49XhxoC55+lNwk55S2z5vWv8pb3vDnHbCcAK4Bw4C1jzE4RmQpkGWMWAW8CM0UkG6unO6K07UophVkppZSP6VCDUkoFmBZepZQKMC28Iaa0E6+VUuWfFt4gEpGLRCTKeb8XQGnfhoaK4m8Q5eUNwzVnecmsKh4tvMGVCLwnIo8CT4h4/WuboBIROf0GISJ3ikiX8vCGISJhLrkHY+3/kFEe3ghEJNrlfstgZinPtPAGwel/YMaYNcAPwN+AvxhjjohIpaCG84JL8UoBrsL9J5UhyxhzCkBELgNGAfbgJjqj2JvZcBEZFOxMxYlIGNBTRF4SkT8D94lIrWDnKo/0dLIAc/a6TheA8UB9rF+69ABGG2N2BzOft0SkGTAT2GKMud35j9KEcs/X+YbXHVgJTDDGvCEiVY0xvwc32Rkici8wGBjveiy4HjfBJiKbsa6v0NYYc0hEKhljTgY7V3miPd4Acym61wBtgH8bY/4KLAPeF5F6IjJWRKYEM2dxHj4G24G3gW4icp0x5pQxxoTax2XXPMayBvgP8JBz2e/OS/8FnYg0B1KNMZcD34jI1SLyVzhz3AQpl+u4eBVgNbAOeFJEIrTolp32eANERC4FqgKfAhcCh4E0Y8yg0x8znb+GuQyIBG42xmwLXuIzin0MHgFcDOwEtgE9sX6p844x5sPgpSypWO5BWJ8sdhhjskTkXaw3vo7GGIeIhBtjHEHMdwHWhVVWYl0L4ChQGeuyhIuMMSUuwB2EjPHAcWOM3fn4fSDCGDNURLoDVYwxK4KRs7zRHm/gRAF7gXrGmO+AbkAfEbn+9IFtjJkC3Ab0DZWiC25jun8C7sQqDGnA5cByrGuUThKR1KCF9MAl9z1YuWOAV0XkGmPMaGALsN/5MT6YRXcCcBfwG9ZFtQ8ALxhjxmL1zH8L1icJl4x3AW8A74rIG86hpVuBcBHZhHUB8OxgZCyXjDF68+MN56cK5/0GwCZgqPNxD+A4MDLYOUv5G8KAelgXe66D9cXUaiDc+XxNYCjQINhZPezzi4H3nPf/AizF6pmdfv51oGkQs94KrAdiPTw3AdgKtAry/rwR+NR5/wngV6xrFpx+fgjQONj/38vTTYca/My1Z+N8PBKrV/OaMWa+iFwBfAIMN8bMDVbO4orndi57AOujbzWsXvkpEbkb+MiEUA/9NBFpAhzEesOoAlQHBhljTorIKKyrSAXlzAZnj7Ey1njzDKziOxxoD+zBGj9/A3jYGLMjwNmKH7NtgJ+AfkBvYDRWB2IrMMwYUxjIfBWBDjX4iYg0BOujmoiMEpHHRaSdMeY94CXgTueXUp8CXbHGS0NCsY/Bd4jIfS4fdW3APc6iOxQYB5wIVtazEZEWwMNYPd5tQGOsInZSRMYB9xHgScCLDReIsc6mWAxMAd7B+lSRBTTBusrVyGAWXRGpLSK1nG+qp2deeN0YcwyYhTV0ExXIfBWFXhbSD0SkDvCyiCwBvsP6yKUr2nUAAAwtSURBVLgFeFhE5htj/iMiBpgqIoXGurRcyHD5h3cPMAi43fkG8jzW6W9/dZ5IfzFwvTEmFMf2DNYQSGOsolYTa3x3G9AFq6eWE9BAZ/brKKClWFPO7ADGArnGmKPOLy9bAdWMMb8GMl+xjPdidQgai8g0rE9l24FUEenkzDjEGPNDoDNWBFp4/eNX4F9Y3/bHAv2NMd+JyBigu7NTMUtECrHODggJxXo7NbDOsOgL1HYWi3bAC1hFrS5wyBhzOFh5PXH2dPcZY7JFZDHwInAN1tjkIqzhhseMMUH50Yfzhwc3As8ArwD/MNb5xOHO87rvwRp2CmjRFZGOWNeb/QroAAwDegF9sH4kUwn4L1DgXH5/oN+4KhItvD50+iR3Y50bugw4ifXlzQTgIWPMDGdPt7+zpzsnqIGLcSm6LY0xXzpPcXoPKMT6uN4emGiMmQx8HbykZ3g43ek+IEZEbgEWYPXQk4wxq7A+xgczXyWsU9gGYr2hfQX829m0HlZRG2yM+f/2zjxWqvqK45+vWK0IatOKRqpFwQWLFUXUaFxqkbpERWoV6oYbAkrVVhODS7WxKRFTa1VcqqnRgopRGiq1KlYpIuKCUuoCBhRibaNoBTFYFb794/wGhyfig/ecGXjnk0wyc++Pe8+9vDn3zFlfrbGMRxIPpt8QGStbArNtLwbGSXqfeIAdafs6SaOdubstIhVvK1G+YJXiiHOAucAkYBgwWNK5tm+wfaekTwjroeEoSfxXlTzX44AjgGdtv1G+oCdK2sT20roKyuf9kUS63vnAcGAkUcq8N1Fl9Wid5RtIZILMJ1LxltjuU/YNJwJVY13jQglJBxFK9UTb08u22cARkvaxPd32I5KmET7decSDOGkBqXhbiaov2HnET8lTHWNDJgHLgdMltbd9te276ynrl7AYGE+UrW5q+x5Ykcc5CDipEZQurHTPhwFHEgGpvxFK9zuEH7I/0FXSVsDbTTM1aiTfMcCZRPHMPCIYeUPZNwA4m8i2qEd1Wi/getvTFVVonwKvE5WJ/UvWzUIi7/xyWHc66DUyqXhbgYplI6kTYSH2BxaVqP+3COv2LmCgog3k+432x1udXiXpUcJNcqSkZSXN7dtEIO3lugrK5yzJI4hfFccQvshuwAjg6uLnnQF84ihaqYesexHFG/fZflPSI8COwAnF0t0cGGD7tRrLVbmH2wOLyuZlxV22qATUzgF2IbI/jk6fbuuRircFSNrO9oIqJbqMsBgvI9JsFgHdCSPhZkmP1yNSvSqqHhaVL+A+wNWSetl+S9LfiSDKBZI+sP3z+kocSOoN7CppXLG8twQm2p4raQERiR9CFHq8aXtBjeXbsZy7PfA8YTnOBQZImmp7lqRrgA7EQ/k92wtrKSOsZLWOB0aU//fnFWxYMiw+JIKA823/r9Yyrs9kHu9aUiytxyR1ruRn2n4XGA1MAy6xfSaRHL9f+WNuKKVbPm4NYPtc4HpgmqRtioU4i7DWGybHGNiUCFb+qHx+icgUOdj2J44mOO2BrrUWrPjA7yUCfCMIv+03gV8S6ViDJX3X9se237M9px5KtwnTiYY3JxTlu7y4yAYQFYpLU+l+BbgByufWtReRnvQysG/53I5oFgKwWdW604g8ze71lvkLrmM4UUL7J6JHxEbAxUSy/EhCqXWpt5xF1t2Ak8v7A4EngFOJXxZDgDuJisDjiKqqzjWW7zCi+uygqm2/IPoudAc6lc93ADvV+342kb0z4b+dDFwDXEVUz9W1VHl9fqWrYQ2R1Jf4kk8hgjm4NFhRdGi6tlg+mxBNZI53A/bYVYwaGkwojEMIC/FS25dLmgdsRqQ2vVE/KVdiN+DY4nMeK+kK4ArgIyJj4V9EAOu/wGmuYSmwopjkL4QfdLJKj1/bVypKgycQaWTjiYf24lrJ1hwcfv1RRGCyD9E572jbc+or2fpL9mpYAyT9ALgJuJKo2uoEPGj7SUlbln1jbI8v6xuqyXYFSRsRuaQH2x5Wth0AXEjk6dbUL7o6mgTS+hPNeCY6qv++T1hqtzkKUtoBG7gOOablYTuSuKfvStrY5Se6pCeAC2y/UL09abukxbtmLAYG2X5KMW/qJD6L/E+TdL4jcr2ikKLO8gIgqUvFclW0dtyWKIz4qaTDbT9ke0pJGdsVaBjFW6V0exCW48dELjFF+S4HrpO03JGmV9P2jlVyTiyyPCNpL0dwqjKZYVFFrlS6CaTiXSNsPwsrKtRmlyKDk4F+5Ys/vaxriBEtsCIIeJ2kPYlqqT2AX9ueX+Q/QdKuhF+3G+GTbigk7QCcR/gdf1s2n1ju+VhFwUrdU51sP6TorftclfI9hQhg/qfO4iUNRLoaWkhJH/oJEb0eU1G+jYBivNC1xPyupyWNJXx4O9heIqkzkac5mPBX3+Q6t3dsknFRvf04ornNfCL74nBKUM32uNpKuXokHU6kYY0mHsyDXeMuY0ljk4q3FZC0C9HF63bbb9dbHlgRBLyLCAKOsD1HMRF2DPCp7WOr1m5A+EbrXgpaVT2FYgT7dravLZ/7AYcS43tuknQYMKuWgbTmopjG8QCwh+2GaYSUNAapeFsJNdCk1SZBwK35LAg4pSjfG4luUwNXZV3WC0mHAqcT+a8zCSv898CNtm8pa64kGnLfavvmesnaHBQl4g3XqzipP1lA0Uo0itItVIKAY4hG2x8TQcD9HR2nziEGb/6hjjKuRLFefwU8RRRJHE/IXWkyNLQsfQl4hkjNamhS6SZfRFq86zGV7Irihz6ZKJCYULIyOgIdbb9VXylX5MEuBI6x/WfF9I5RwD22x0vaH7ifqKLbHTgqc0yTdZm0eNdjKtkVjgYsdxFTbAcq2v190AhKF8D2e4T7YKRi1MwCovVgp7J/KrAXcQ0/TKWbrOtkOlkbwfZrku4lgoCv11ueplTlwT4v6WGi8u9OAEntHJ2x6p4yliStQboa2hiNFARcFaWU+RFga9tvN2r1X5K0hHQ1tDEaWekC2J5ENDV/XFKnVLrJ+ki6GpKGo1SAbQT8VdFI3I2U9pYkLSVdDUnDIqmD7SX1liNJWptUvEmSJDUmfbxJkiQ1JhVvkiRJjUnFmyRJUmNS8SZJktSYVLzJWiFpmaQXJf1T0n2S2rfgWAdLerC8P1rSxatZu4WkYWtxjiskXdjc7U3W3FH6ATf3XF0kZf/d5AtJxZusLUtt97Tdg+giNqR6p4I1/vuyPcH2yNUs2YLoWJYk6yypeJPWYArQrVh6r0gaTYxY31ZSX0nTJM0olnEHiDaQkl6V9CTQv3IgSYMk3VDebyVpvKSZ5bUfMVCya7G2R5V1F0l6VtI/Sr/eyrEukTRb0iRg5y+7CElnlePMlHR/Eyu+j6QpkuaUJudIaidpVNW5z27pjUzaBql4kxYhaUNiDM+ssmlnYhzPHsCHwKVAH9t7As8BP5P0daLB+VHAAUSz9lXxO2Cy7d2BPYlevBcDc4u1fVGZtLEjsDfQE+gl6UBJvYABxIy5/kDvZlzOA7Z7l/O9ApxRta8LcBBRznxzuYYzgEW2e5fjnyVp+2acJ2njZMlwsrZsIunF8n4KcDuwDTDf9tNl+77E1OKpkiD6AU8j5ry9XtpVIumPxNy3phwCnAJgexmwSNI3mqzpW14vlM8dCEXcERhfaUYuaUIzrqmHpKsId0YH4OGqfeNKm83XJM0r19AX+F6V/3fzcu5sW5msllS8ydqy1HbP6g1FuX5YvQl41PbAJut6Aq1VMiliavItTc5x/lqc4w6gn+2ZkgYBB1fta3osl3MPt12toJHUZQ3Pm7Qx0tWQfJU8DewvqRvEDDJJOxFj2reX1LWsG/gF//4xYGj5t+3KvLgPCGu2wsPA6VW+486SOhHTKo6VtEmZtnFUM+TtCPxb0teAE5vs+7GkDYrMOwCzy7mHlvVI2knSps04T9LGSYs3+cqw/U6xHO+WtHHZfGmZeDwYmChpIfAk0GMVhzgPuFXSGcAyYKjtaZKmlnSth4qftzswrVjcS4CTbM8ojd9fJEbCT2mGyJcB08v6Ways4GcDk4GtgCG2P5J0G+H7naE4+TtAv+bdnaQtk01ykiRJaky6GpIkSWpMKt4kSZIak4o3SZKkxqTiTZIkqTGpeJMkSWpMKt4kSZIak4o3SZKkxvwfT/VHMJXiqmEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "   \n",
    "    cmap=plt.cm.Blues\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], \".2f\"),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels_text)\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where((y_test == i) & (preds != i))[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(X_test[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"GT: {}\\n Pred: {}\".format(labels_text[y_test[k]], labels_text[preds[k]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> A la vista de los resultados obtenidos y de la matriz de confusión podemos plantearnos responder a las cuestiones:\n",
    "<ol>\n",
    "    <li>¿Cómo son los errores?</li>\n",
    "    <li>¿Parecen razonables?</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    <ul>\n",
    "<li>Es interesante notar que cuando el modelo predice \"Trouser\" casi nunca se equivoca: 97% acierto.\n",
    "<li>La confusión más grande aparece entre \"Pullover\" y \"Coat\": 18% Pullover y 17% Coat.\n",
    "<li>Viendo algunos ejemplos parece razonable que el modelo confunda algunas imágenes de \"Pullover\" con \"Coat\" y viceversa. También las confusiones entre \"T-shirt\" y \"Pullover\" o \"Dress\" y \"Coat\" podrían justificarse.    \n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "Como continuación de la práctica, en esta segunda parte clasificaremos las imágenes de ropa utilizando el algoritmo SVM con el kernel radial. En este caso, en lugar de utilizar una búsqueda de rejilla para ajustar los hiperparámetros del algoritmo utilizaremos una búsqueda aleatoria, es decir, probaremos combinaciones de parámetros al azar. Los hiperparámetros a optimizar son:\n",
    "\n",
    "<ul>\n",
    "<li>C: el valor de penalización de los errores en la clasificación. Marca el compromiso entre obtener el hiperplano con el mayor margen posible y clasificar el máximo número de ejemplos correctamente. Probaremos valores aleatorios distribuidos uniformemente entre 1 y 500.</li>\n",
    "<li> gamma: coeficiente que multiplica la distancia entre dos puntos en el kernel radial. Probaremos valores aleatorios distribuidos uniformemente entre 0.001 y 0.1</li>\n",
    "</ul>\n",
    "Igual que en el caso anterior, para validar el rendimiento del algoritmo con cada combinación de hiperparámetros utilizaremos validación cruzada (cross-validation) con 4 particiones estratificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo del valor óptimo de hiperparámetros\n",
    "<br>\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> En este primer paso calculamos el valor óptimo de los hiperparámetros C y gamma utilizando 10 combinaciones de parámetros elegidas al azar. Para ello utilizaremos los módulos RandomizedSearchCV y svm de sklearn, así como el módulo uniform de scipy.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La búsqueda llevó 83.76783585548401 segundos\n",
      "1) Precisión media: 88.30 +/- 0.92 con parámetros {'C': 235.89223684051302, 'gamma': 0.053467178358976214}\n",
      "1) Precisión media: 88.30 +/- 1.02 con parámetros {'C': 30.320067894146817, 'gamma': 0.05598437958241016}\n",
      "8) Precisión media: 87.00 +/- 1.12 con parámetros {'C': 274.3042185133532, 'gamma': 0.09289969025969598}\n",
      "6) Precisión media: 87.60 +/- 0.96 con parámetros {'C': 370.08824460737196, 'gamma': 0.07568078934708235}\n",
      "10) Precisión media: 86.90 +/- 1.06 con parámetros {'C': 135.28519457795068, 'gamma': 0.09966378055337108}\n",
      "3) Precisión media: 88.25 +/- 1.06 con parámetros {'C': 342.62523219493136, 'gamma': 0.0545744865426032}\n",
      "5) Precisión media: 87.72 +/- 0.95 con parámetros {'C': 136.6134260790927, 'gamma': 0.021235453205188683}\n",
      "7) Precisión media: 87.30 +/- 1.12 con parámetros {'C': 30.475049491885287, 'gamma': 0.08643278789094584}\n",
      "8) Precisión media: 87.00 +/- 1.29 con parámetros {'C': 197.9396297634492, 'gamma': 0.0029191470264940504}\n",
      "4) Precisión media: 87.83 +/- 1.03 con parámetros {'C': 111.59301855323184, 'gamma': 0.02265698441747537}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from time import time\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "param_dist = {\"C\": sp_rand(loc=1, scale=500), \"gamma\": sp_rand(loc=0.001, scale=0.1)}\n",
    "\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search, cv=4)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train_pca, y_train)\n",
    "end = time()\n",
    "\n",
    "print(\"La búsqueda llevó {} segundos\".format(end - start))\n",
    "\n",
    "means = random_search.cv_results_[\"mean_test_score\"]\n",
    "stds = random_search.cv_results_[\"std_test_score\"]\n",
    "params = random_search.cv_results_['params']\n",
    "ranks = random_search.cv_results_['rank_test_score']\n",
    "\n",
    "for rank, mean, std, pms in zip(ranks, means, stds, params):\n",
    "    print(\"{}) Precisión media: {:.2f} +/- {:.2f} con parámetros {}\".format(rank, mean*100, std*100, pms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué parámetros han dado mejores resultados? ¿Qué variación hay entre las diferentes combinaciones de parámetros? ¿Es significativa la variación entre las diferentes combinaciones? ¿Hay algún parámetro que influya más que el otro? ¿Era de esperar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solución: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    <ul>\n",
    "<li>La mejor combinación se da con C = 245 y gamma = 0.034.\n",
    "<li>Las diferencias en la precisión no son demasiado grandes, por lo que, teniendo en cuenta la desviación estandard es difícil afirmar que haya combinaciones claramente mejores que otras.\n",
    "<li>Las mejores soluciones se dan con gamma del orden de 0.03-0.04. Se puede ver que en las mejores soluciones el valor de C es bastante variable, por lo que podemos deducir que el parámetro gamma tiene mucho más peso, lo cual es típico al utilizar el kernel radial.  \n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> entrenar un modelo SVM con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostrar la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solución: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valor óptimo para C: {}\".format(random_search.best_params_[\"C\"]))\n",
    "print(\"Valor óptimo para gamma: {}\".format(random_search.best_params_[\"gamma\"]))\n",
    "\n",
    "clf = svm.SVC(C=random_search.best_params_[\"C\"], gamma=random_search.best_params_[\"gamma\"])\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_pca)\n",
    "\n",
    "accuracy = np.true_divide(np.sum(preds == y_test), preds.shape[0])*100\n",
    "print(\"Precisión en el conjunto de test: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> mostrar la matriz de confusión del modelo y algunas imágenes que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solución: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels_text)\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where((y_test == i) & (preds != i))[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(X_test[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"GT: {}\\n Pred: {}\".format(labels_text[y_test[k]], labels_text[preds[k]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Cómo son los errores? ¿Parecen razonables?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solución: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    <ul>\n",
    "<li>Este modelo parece clasificar ligeramente mejor las imágenes con \"Coat\" y \"Pullover\" que el modelo anterior, pero un poco peor las imágenes de \"Dress\".\n",
    "<li>La mayor confusión para este modelo está también entre \"Pullover\" y \"Coat\", seguido de la confusión entre \"T-shirt\" y \"Dress\".\n",
    "<li>En este caso el modelo se equivoca en alguna predicción de \"Trouser\", pero tambien es la prenda que mejor clasifica como en el modelo anterior.\n",
    "<li>Viendo algunos ejemplos de errores estos parecen bastante razonables.    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Redes neuronales (4 puntos)\n",
    "\n",
    "Como tercer ejercicio utilizaremos una red neuronal para clasificar las imágenes de ropa. Utilizaremos también ahora una búsqueda aleatoria para ajustar los hiperparámetros de la red neuronal. En particular, utilizaremos una red monocapa con 4 salidas (una para cada clase del conjunto de datos) entrenada con el método de retropropagación y el optimizador SGD. Las neuronas de la capa oculta tendrán como activación la función sigmoide. Los hiperparámetros a ajustar en este caso son los siguientes:\n",
    "\n",
    "- Número de neuronas de la capa oculta: probaremos valores entre 20 y 200.\n",
    "- Número de épocas de entrenamiento: probaremos valores entre 10 y 50.\n",
    "- Velocidad de aprendizaje (learning rate): probaremos valores entre 0.001 y 0.2.\n",
    "\n",
    "El procedimiento para validar el rendimiento del modelo para cada combinación de parámetros será el mismo que en los casos anteriores: validación cruzada con 4 particiones generadas de forma estratificada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> cálculo del valor óptimo del número de neuronas de la capa oculta, el número de épocas de entrenamiento y la velocidad de aprendizaje utilizando 10 combinaciones de parámetros elegidas al azar. Podéis utilizar los módulos Sequential, Dense y SGD de keras, además de uniform y randint de scipy y StratifiedKFold de sklearn.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solución: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from scipy.stats import randint\n",
    "from time import time\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4)\n",
    "\n",
    "n_iter_search = 10\n",
    "params = np.zeros((n_iter_search, 3))\n",
    "\n",
    "n_neurons_dist = randint(low=20, high=200)\n",
    "n_epochs_dist = randint(low=10, high=50)\n",
    "lr_dist = sp_rand(loc=0.001, scale=0.2)\n",
    "\n",
    "best_it = -1\n",
    "max_score = 0\n",
    "    \n",
    "start = time()\n",
    "for i in range(n_iter_search):\n",
    "    n_neurons = n_neurons_dist.rvs()\n",
    "    n_epochs = n_epochs_dist.rvs()\n",
    "    lr = lr_dist.rvs()\n",
    "    \n",
    "    params[i, 0] = n_neurons\n",
    "    params[i, 1] = n_epochs\n",
    "    params[i, 2] = lr\n",
    "    \n",
    "    print(\"Prueba {}\".format(i))\n",
    "    print(\"Número de neuronas: {}; Número de épocas: {}; Velocidad de aprendizaje: {}\".format(n_neurons, n_epochs, lr))\n",
    "\n",
    "    scores = np.zeros(4)\n",
    "    j = 0\n",
    "    for train_index, test_index in kf.split(X_train_pca, y_train):\n",
    "        X_train_kf, X_test_kf = X_train_pca[train_index], X_train_pca[test_index]\n",
    "        y_train_kf, y_test_kf = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        y_train_kf = keras.utils.to_categorical(y_train_kf, num_classes=n_classes)\n",
    "        y_test_kf = keras.utils.to_categorical(y_test_kf, num_classes=n_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(n_neurons, input_shape=(100,), activation=\"sigmoid\"))\n",
    "        model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=SGD(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        model.fit(X_train_kf, y_train_kf, epochs=n_epochs, verbose=0)\n",
    "        \n",
    "        score = model.evaluate(X_test_kf, y_test_kf, verbose=0)\n",
    "        scores[j] = score[1]\n",
    "        j += 1\n",
    "        \n",
    "    score_mean = np.mean(scores)\n",
    "    score_std = np.std(scores)\n",
    "    print(\"Precisión media: {:.2f} +/- {:.2f}\".format(score_mean*100, score_std*100))\n",
    "        \n",
    "    if (score_mean > max_score):\n",
    "        max_score = score_mean\n",
    "        best_it = i\n",
    "\n",
    "end = time()\n",
    "\n",
    "print(\"La búsqueda llevó {} segundos\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Qué parámetros han dado mejores resultados? ¿Qué variación hay entre las diferentes combinaciones de parámetros? ¿Es significativa la variación entre las diferentes combinaciones? ¿Hay algún parámetro que influya más que los otros? ¿Era de esperar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solución: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    <ul>\n",
    "<li>La mayor precisión se obtiene con 23 neuronas en la capa oculta y entrenando 40 épocas con una velocidad de aprendizaje de 0.119.\n",
    "<li>En este caso podemos ver mayor variabilidad entre las precisiones medias para cada combinación por lo que, aun teniendo en cuenta las desviaciones estandard podemos afirmar que algunas soluciones son mejores que otras.\n",
    "<li>Con pocas pruebas y las desviaciones estandard altas es difícil extraer relaciones claras entre hiperparámetros, pero parece aflorar que las velocidades de aprendizaje más bajas dan peores resultados en la precisión, lo cual es quiere decir que probablemente se debería haber entrenado durante más épocas.</ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> entrenar una red neuronal con los valores de los hiperparámetros óptimos utilizando todo el conjunto *X_train_pca* y mostrar la precisión de la predicción del modelo en el conjunto *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de neuronas óptimo: {}\".format(params[best_it, 0]))\n",
    "print(\"Número de épocas óptimo: {}\".format(params[best_it, 1]))\n",
    "print(\"Velocidad de aprendizaje óptima: {}\".format(params[best_it, 2]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(int(params[best_it, 0]), input_shape=(100,)))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=SGD(lr=params[best_it, 2]), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_pca, keras.utils.to_categorical(y_train, num_classes=n_classes), epochs=int(params[best_it, 1]), verbose=0)\n",
    "\n",
    "preds = np.argmax(model.predict(X_test_pca, verbose=0), axis=1)\n",
    "\n",
    "accuracy = np.true_divide(np.sum(preds == y_test), preds.shape[0])*100\n",
    "print(\"Precisión en el conjunto de test: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> mostrar la matriz de confusión del modelo y algunas imágenes que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels_text)\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where((y_test == i) & (preds != i))[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(X_test[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"GT: {}\\n Pred: {}\".format(labels_text[y_test[k]], labels_text[preds[k]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Cómo son los errores? ¿Parecen razonables?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solución: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<ul>\n",
    "<li>Este modelo confunde muchas \"T-shirt\" con \"Dress\" y muchos \"Pullover\" con \"Coat\". Esto por su parte conlleva a la vez que el modelo prediga mejor la clase \"Coat\" que los otros modelos.\n",
    "<li>En el caso de \"Trouser\" lo clasifica con mucha seguridad, pero aún así se equivoca ligeramente más que los modelos anteriores.\n",
    "<li>Viendo algunos ejemplos parece razonable que el modelo confunda algunas imágenes de \"T-shirt\" con \"Dress\" y viceversa.    \n",
    "</ul>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimización de métricas (2 puntos)\n",
    "\n",
    "En los ejercicios anteriores hemos buscado siempre el modelo que mejor precisión obtiene en general, pero esto no es siempre los más adecuado. Por ejemplo, imaginemos que necesitamos el modelo para una empresa que únicamente vende pantalones y está haciendo un estudio sobre las imágenes de pantalones que obtiene de Internet. En este escenario, imaginemos que la empresa quiere estudiar el máximo número posible de imágenes de pantalones, por lo que está muy interesada en que el modelo no clasifique erróneamente imágenes de pantalones (asumiendo si es necesario que para ello habrá imágenes clasificadas como pantalones que en realidad no lo sean).\n",
    "\n",
    "La misma idea de utilidad del modelo se puede encontrar, aunque con un ejemplo más complejo, en [este enlace](http://blog.mldb.ai/blog/posts/2016/01/ml-meets-economics/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Definir una función que, dada la predicción del modelo para un conjunto de imágenes y las etiquetas reales de los datos, devuelva un coste de forma que los errores de clasificar un pantalón como otra prenda tengan el doble de peso que los otros errores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import backend\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Utilizar la función definida anteriormente junto con el código de entrenamiento de la red neuronal para optimizar los hiperparámetros de la red según la nueva métrica.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "for i in range(n_iter_search):\n",
    "    n_neurons = n_neurons_dist.rvs()\n",
    "    n_epochs = n_epochs_dist.rvs()\n",
    "    lr = lr_dist.rvs()\n",
    "    \n",
    "    params[i, 0] = n_neurons\n",
    "    params[i, 1] = n_epochs\n",
    "    params[i, 2] = lr\n",
    "    \n",
    "    print(\"Prueba {}\".format(i))\n",
    "    print(\"Número de neuronas: {}; Número de épocas: {}; Velocidad de aprendizaje: {}\".format(n_neurons, n_epochs, lr))\n",
    "\n",
    "    scores = np.zeros(4)\n",
    "    j = 0\n",
    "    for train_index, test_index in kf.split(X_train_pca, y_train):\n",
    "        X_train_kf, X_test_kf = X_train_pca[train_index], X_train_pca[test_index]\n",
    "        y_train_kf, y_test_kf = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        y_train_kf = keras.utils.to_categorical(y_train_kf, num_classes=n_classes)\n",
    "        y_test_kf = keras.utils.to_categorical(y_test_kf, num_classes=n_classes)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(n_neurons, input_shape=(100,), activation=\"sigmoid\"))\n",
    "        model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=SGD(lr=lr), loss='categorical_crossentropy', metrics=[auc])\n",
    "\n",
    "        model.fit(X_train_kf, y_train_kf, epochs=n_epochs, verbose=0)\n",
    "        \n",
    "        score = model.evaluate(X_test_kf, y_test_kf, verbose=0)\n",
    "        scores[j] = score[1]\n",
    "        j += 1\n",
    "        \n",
    "    score_mean = np.mean(scores)\n",
    "    score_std = np.std(scores)\n",
    "    print(\"Precisión media: {:.2f} +/- {:.2f}\".format(score_mean*100, score_std*100))\n",
    "        \n",
    "    if (score_mean > max_score):\n",
    "        max_score = score_mean\n",
    "        best_it = i\n",
    "\n",
    "end = time()\n",
    "\n",
    "print(\"La búsqueda llevó {} segundos\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> ¿Han cambiado significativamente los mejores valores de los hiperparámetros? ¿Cuál crees que puede ser la razón?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Solución: </b>\n",
    "<div style=\"background-color: #FCF2F2; border-color: #dfb5b4; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Efectivamente, han cambiado significativamente los resultados de la prueba. Se han incrementado los resultados de precisión en todas las pruebas, aunque se ha manteniddo la velocidad de aprendizaje en los mismos rangos o similares.<br>\n",
    "    <ul>\n",
    "<li>La mayor precisión se obtiene con 104 neuronas en la capa oculta y entrenando 39 épocas con una velocidad de aprendizaje de 0.186.\n",
    "<li>En este caso podemos ver escasa variabilidad entre las precisiones medias para cada combinación.\n",
    "<li>Desviaciones estandard muy bajas.</ul>\n",
    "\n",
    "Al cambiar las metricas estandard 'metrics=['accuracy'] por las personalizadas que hemos construido en la función 'auc()', se consigue que la red entrene de manera mas eficiente las capas de aprendizaje.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.855 · Modelos avanzados de minería de datos · PEC4</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2018-1 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PEC 4: Combinación de clasificadores\n",
    "\n",
    "En esta práctica veremos diferentes métodos de combinación de clasificadores aplicados sobre el conjunto de datos [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) (ya usado en la práctica PEC 3).\n",
    "\n",
    "<ol start=\"0\">\n",
    "  <li>Carga de datos</li>\n",
    "  <li>Combinación paralela de clasificadores base similares\n",
    "  <br>1.1 Bagging\n",
    "  <br>. 1.1.1 Random Forest simple\n",
    "  <br>. 1.1.2 Out-of-bag\n",
    "  <br>. 1.1.3 Probabilidad por clase\n",
    "  <br>. 1.1.4 Importancia de las variables\n",
    "  <br>. 1.1.5 Número de clasificadores\n",
    "  <br>. 1.1.6 Volumen de datos\n",
    "  <br>1.2 Boosting</li>\n",
    "  <li>Combinación secuencial de clasificadores base diferentes\n",
    "  <br>2.1 Stacking\n",
    "  <br>2.2 Cascading\n",
    "  <br>. 2.2.1 Cascading simple\n",
    "  <br>. 2.2.2 Cascading con variables adicionales</li>\n",
    "</ol>\n",
    "\n",
    "**Importante: Cada uno de los ejercicios puede suponer varios minutos de ejecución, por lo que la entrega debe hacerse en formato notebook y en formato html donde se vea el código y los resultados y comentarios de cada ejercicio. Para exportar el notebook a html puede hacerse desde el menú File $\\to$ Download as $\\to$ HTML.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos los mismos datos que en la práctica anterior, PEC 3, que son las 5.000 imágenes Fashion MNIST, correspondientes a 5 tipos de prendas de ropa distintos: \"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\" y \"Coat\".\n",
    "\n",
    "El siguiente código cargará las imágenes y mostrará un ejemplo de imagen de cada una de las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "images = data[\"images\"]\n",
    "labels = data[\"labels\"]\n",
    "n_classes = 5\n",
    "labels_text = [\"T-shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "\n",
    "idxs = [np.where(labels == i)[0] for i in range(n_classes)]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    k = np.random.choice(idxs[i])\n",
    "    ax[i].imshow(images[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"{}\".format(labels_text[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como en la PEC 3, reducimos dimensionalidad usando PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=2017, stratify=labels)\n",
    "\n",
    "pca = PCA(n_components=100, random_state=2017)\n",
    "pca_fit = pca.fit(X_train)\n",
    "X_train_pca = pca_fit.transform(X_train)\n",
    "X_test_pca = pca_fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Combinación paralela de clasificadores base similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Random forest simple (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea básica del *bagging* es utilizar el conjunto de entrenamiento original para generar centenares o miles de conjuntos similares usando muestreo con reemplazo. En este concepto está basado el algoritmo *Random Forest*, la combinación de varios árboles de decisión, cada uno entrenado con una realización diferente de los datos. La decisión final del clasificador combinado (la *Random Forest*) se toma por mayoría, dando el mismo peso a todas las decisiones parciales tomadas por los clasificadores base (los árboles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Usando los conjuntos *X_train_pca* e *y_train_pca*, entrenar un modelo *Random Forest* con 100 árboles de decisión y estimar la precisión del modelo con una estrategia de *cross-validation* en los mismos conjuntos.\n",
    "<hr>\n",
    "Sugerencia: usar los módulos *RandomForestClassifier* y *cross_val_score* de sklearn. Para aprender más sobre *cross validation* y sobre como usar estes módulos, os recomendamos los siguientes enlaces:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html<br>\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "from time import time\n",
    "\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "cvscores = cross_val_score(clf, X_train_pca, y_train, cv=5)\n",
    "\n",
    "print(\"Precisión media obtenida con cross-validation (CV): {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Out-of-bag (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una ventaja del *bagging* usado en el *Random Forest* es que cada uno de los árboles de decisión ha sido entrenado con una combinación diferente de los datos (muestreo con reemplazo), o sea que cada uno de los árboles no ha visto una determinada parte de los datos originales. Esto define una especie de conjunto de test para cada uno de los árboles, llamado *out-of-bag*, que puede ser usado para estimar el error del modelo sin necesidad de usar el conjunto de test real que creamos previamente, ni de usar estrategias de *cross-validation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Usando los conjuntos *X_train_pca* e *y_train_pca*, entrenar un modelo Random Forest con 100 árboles de decisión. Mostrar la precisión de este modelo en el *out-of-bag* y en el conjunto *X_test_pca*.\n",
    "<hr>\n",
    "Sugerencia: usar el módulo *RandomForestClassifier* de sklearn. Para aprender más sobre *out-of-bag* y sobre como usar este módulo (incluyendo el atributo *oob&#95;score_*), os recomendamos los siguientes enlaces:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html<br>\n",
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=100, oob_score=True, random_state=2017)\n",
    "\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"Precisión de este modelo con uso de Out-of-bag: {:.2f} %\".format(clf.oob_score_*100))\n",
    "\n",
    "preds_rfc = clf.predict(X_test_pca)\n",
    "accuracy = np.true_divide(np.sum(preds_rfc == y_test), preds_rfc.shape[0])*100\n",
    "print(\"Precisión en el conjunto de test: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> La precisión obtenida en el *out-of-bag* y en el conjunto de test son comparables? Era de esperar? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "<ul>\n",
    "<li>La precisión medida con el uso de 'out-of-bag' y la obtenida en el conjunto de test son muy parecidas (aprox. una diferencia de 0,15).</li>\n",
    "<li>Este resultado era de esperar porque: \n",
    "    <ul>\n",
    "<li>la estimación del error con el out-of-bag es un método robusto y nos da el error del modelo en el conjunto de datos X_train_pca</li>\n",
    "<li>el error en el conjunto de datos de test X_test_pca es muy parecido porque X_test_pca tiene la misma estructura (fue creado con separación aleatoria estratificada) que el conjunto de datos de entrenamiento X_train_pca</li>\n",
    "</ul>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Probabilidad por clase (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra ventaja del *bagging* usado en el *Random Forest* es que cada uno de los árboles de decisión, entrenado con una combinación diferente de los datos, puede obtener un resultado diferente. En los problemas de clasificación, el resultado de cada árbol se considera como un voto diferente, y la predicción final del modelo es la clase que haya obtenido más votos teniendo en cuenta todos los árboles.\n",
    "\n",
    "Estos votos individuales de los árboles también se pueden usar para estimar la probabilidad con la que el modelo prevé cada una de las clases, siendo la probabilidad para cada clase igual al número de votos obtenidos para aquella clase dividido entre el número de árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Para cada clase (etiqueta), muestra un ejemplo de imágen que el modelo haya clasificado incorrectamente junto con la etiqueta asignada por el modelo y la etiqueta original. Muestra también las probabilidades que el modelo ha atribuído a cada clase para estas imágenes.\n",
    "<hr> Sugerencia: usa el modelo que entrenaste en el ejercicio anterior con el módulo *RandomForestClassifier* de sklearn y las previsiones que calculaste para el conjunto de datos de test. Para mostrar las imágenes, usa el código proporcionado en la sección 0. Para aprender más sobre el módulo *RandomForestClassifier* de sklearn (incluyendo el método *predict_proba*), os recomendamos el siguiente enlace:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Obtener los índices de la primera imagen mal identificada para cada clase:\n",
    "idxs = [np.where((y_test == i) & (preds_rfc != i))[0][0] for i in range(n_classes)]\n",
    "\n",
    "# Mostrar las imágenes junto con las etiquetas actuales y previstas:\n",
    "fig, ax = plt.subplots(1, n_classes, figsize=(10,10))\n",
    "for i in range(n_classes):\n",
    "    k = idxs[i]\n",
    "    ax[i].imshow(X_test[k].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i].set_title(\"Imagen n: {}\\nActual: {}\\n Pred: {}\".format(k, labels_text[y_test[k]], labels_text[preds_rfc[k]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las probabilidades de cada clase para cada imagen:\n",
    "probs_rfc = clf.predict_proba(X_test_pca)\n",
    "\n",
    "# Mostrar las probabilidades junto con la clase prevista (probabilidad més alta) y la real\n",
    "print(\"Etiquetas: \\t\\t\\t{}\".format(labels_text))\n",
    "for i in range(n_classes):\n",
    "    k = idxs[i]\n",
    "    print(\"Probabilidades imagen {}:\\t{}; Actual: '{}'; Pred: '{}'\".format(k, probs_rfc[k], labels_text[y_test[k]], labels_text[preds_rfc[k]]))\n",
    "\n",
    "# Adicional: calcular cuantas veces la segunda clase con más probabilidad era la correcta:\n",
    "n_max_prob_correct = 0\n",
    "n_2nd_max_prob_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == np.argmax(probs_rfc[i]):\n",
    "        n_max_prob_correct += 1\n",
    "    elif y_test[i] == probs_rfc[i].argsort()[-2]:\n",
    "        n_2nd_max_prob_correct += 1\n",
    "print(\"\\nCuantas veces el modelo acertó? (precisión): {}%\\nDe las veces que no acertó, cuantas veces la segunda clase más votada era la correcta?: {:.1f}%\" \\\n",
    "      .format(float(n_max_prob_correct)/len(y_test)*100, \n",
    "              float(n_2nd_max_prob_correct)/(len(y_test)-n_max_prob_correct)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> En estos casos en los que el modelo se equivocó, estaba cerca de prever la etiqueta correcta?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "Sí, aunque el modelo se equivocó, ha estado siempre muy cerca (relativamente) de obtener el resultado correcto.<br>\n",
    "En 4 de los 5 casos analizados, la segunda clase con una probabilidad más alta era la correcta. Esta proporción se mantiene en todo el conjunto de datos de test.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Importancia de las variables (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra ventaja del algoritmo *Random Forest* es que permite medir la importancia relativa de cada variable, gracias a que cada uno de los árboles fué entrenado con un subconjunto diferente de las variables originales.\n",
    "\n",
    "En el problema de clasificación de imágenes analizado aquí, la importancia de las variables nos permite saber cuáles son generalmente los píxeles más importantes par poder clasificar la imágen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Entrena un clasificador *Random Forest* con el conjunto de datos de entrenamiento original *X_train*, en los que cada variable es la intensidad de cada píxel (en vez de ser las variables PCA que usamos anteriormente). Muestra cuáles son las 10 variables más importantes. Haz un gráfico en el que se vea que zonas de una imágen son más importantes para el clasificador.\n",
    "\n",
    "<hr> Sugerencia: usa el módulo *RandomForestClassifier* de sklearn para calcular la importancia de las variables. Para representar gráficamente la importancia de cada píxel de la imagen, usa parte del código proporcionado en la sección 0. Para aprender más sobre el módulo *RandomForestClassifier* de sklearn (incluyendo el método *feature&#95;importances_*), os recomendamos el siguiente enlace:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenar clasificador con datos originales, sin PCA, para que cada variable sea la intensidad de cada píxel:\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=80)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# cálculo de la importancia de las variables y representación gráfica de las top 10:\n",
    "importances = clf.feature_importances_\n",
    "topN = 10\n",
    "indices = np.argsort(importances)\n",
    "n_feats = min(len(importances), topN)\n",
    "labels = np.arange(1, np.shape(X_train)[1]+1) # nombres de las variables, en este caso número del píxel\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.title(\"Variables más importantes (número del píxel)\")\n",
    "plt.barh(range(n_feats), importances[indices][-n_feats:], color=\"b\")\n",
    "plt.yticks(range(n_feats), labels[indices][-n_feats:])\n",
    "plt.ylim([-1, n_feats])\n",
    "plt.show()\n",
    "\n",
    "# representación gráfica de la importancia de cada píxel:\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"Importancia de cada píxel en el clasificador\")\n",
    "plt.imshow(importances.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Te parece plausible el resultado que has obtenido? Porqué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "En el gráfico con la 'Importancia de cada píxel en el clasificador' vemos que hay una zona vertical central que es la más importante, así como una especie de numero ocho difuso alrededor. <br>\n",
    "Parece muy razonable ya que la línea central permite diferenciar los pantalones, mientras que la zona importante alrededor está situada aproximadamente para localizar el contorno de las diferentes prendas de vestir.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Número de clasificadores (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los ejercicios anteriores hemos combinado 100 clasificadores simples en nuestro clasificador combinado. Será que la precisión del clasificador combinado aumenta indefinidamente su desempeño si añadimos más clasificadores?\n",
    "\n",
    "Para responder a esta pregunta vamos a representar una curva de validación. La curva de validación es una representación gráfica del desempeño de un modelo variando uno de sus parámetros. Mientras que la búsqueda de rejilla nos permite encontrar la combinación de parámetros que da mejores resultados, la curva de validación nos permite entender cuál es el impacto de un determinado parámetro en el desempeño de un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Entrena varios modelos de *Random Forest* con un número de árboles cada vez mayor. Para cada modelo, calcula su precisón en el conjunto de test o usando *cross-validation* en el conjunto de entrenamiento. Opcional: representa gráficamente la evolución de la precisión con el número de árboles para ayudarte en el análisis de los resultados.\n",
    "<hr>\n",
    "Sugerencia: usar el módulo *validation_curve* de sklearn. Para aprender a usar este módulo os recomendamos los siguientes enlaces:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html<br>\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#validation-curve\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = np.logspace(0, 3.2, 7).astype(np.int)\n",
    "param_name=\"n_estimators\"\n",
    "train_scores, test_scores = validation_curve(\n",
    "     ensemble.RandomForestClassifier(), X_train_pca, y_train,\n",
    "     param_name=param_name, param_range=param_range,\n",
    "     cv=5, scoring=\"accuracy\", n_jobs=4)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Curva de validación\")\n",
    "plt.xlabel(param_name)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Score de entrenamiento (training)\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Incrementa indefinidamente la precisión con el número de árboles combinados? Si satura, lo hace a la precisión máxima o a otro valor? Porqué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "La precisión no aumenta indefinidamente con el número de árboles combinados, sino que se satura a un valor alrededor del 85%. Añadir más árboles sólo es útil cuando estos añaden información nueva, porque han sido entrenados con datos distintos que permiten al algoritmo mejorar las decisiones tomadas. La parcialidad de un clasificador, por falta de riqueza en los datos o falta de atributos esenciales, no puede ser totalmente solucionada añadiendo nuevos clasificadores parciales.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Volumen de datos (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será que entrenando el modelo con más datos (más imágenes) el modelo aprendería a clasificar con mejor precisión? Es muy útil intentar responder a esta pregunta antes de lanzarse a conseguir más datos, ya que este puede ser un proceso difícil, caro, o que implique esperar mucho tiempo.\n",
    "\n",
    "Para responder a esta pregunta, analizaremos cómo evoluciona la precisión del modelo en los conjuntos de entrenamiento y test para diferentes volúmenes de datos de creciente tamaño. Representar los resultados en una curva de aprendizaje (*learning curve*) nos permitirá analizar visualmente estas cantidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Entrena varios modelos de *Random Forest* con un volumen de datos cada vez mayor. Para cada modelo, calcula su precisón en el conjunto de entrenamiento y de test, y representa los resultados en un gráfico.\n",
    "<hr>\n",
    "Sugerencia: usar el módulo *learning_curve* de sklearn. Para aprender a usar este módulo os recomendamos los siguientes enlaces:<br>\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\"\"\"\n",
    "Esta función corresponde con la original de la fuente:\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html \n",
    "\n",
    "Se han hecho variaciones en el código original\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    # Las siguientes 2 lineas del código original no se usarán:\n",
    "    #if ylim is not None:\n",
    "    #    plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "plot_learning_curve(ensemble.RandomForestClassifier(n_estimators=50), \n",
    "                    \"Learning curve\", \n",
    "                    X_train_pca, y_train, \n",
    "                    cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Crees que si obtuviésemos más datos de entrenamiento (más imágenes clasificadas) mejoraría el modelo? Porqué?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "En el gráfico vemos que la precisión del modelo en el conjunto de datos de entrenamiento es la máxima posible, por lo que el modelo consigue clasificar perfectamente esas imágenes. <br>\n",
    "Sin embargo, la precisión en el conjunto de test está muy por debajo. Esto nos muestra que el modelo no generaliza suficientemente la lógica de clasificación de las imágenes, sino que esta lógica es demasiado específica del conjunto usado para entrenar el modelo. <br>\n",
    "Este problema se conoce como *overfitting* y podría ser solucionado añadiendo más datos (más imágenes clasificadas).<br>\n",
    "Por otro lado, en el gráfico también vemos que la precisión en el conjunto de test aumenta al aumentar el volumen de datos (aunque cada vez más lentamente, se comporta de manera asintótica hacia el valor 0.85), por lo que esperamos que la precisión continúe en aumento si tuviésemos más imágenes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Boosting (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el sistema de *Boosting* se combinan varios clasificadores débiles sequencialmente, y en cada uno de ellos se da más peso a los datos que han sido erróneamente clasificados en las combinaciones anteriores, para que se concentre así en los casos más difíciles de resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Usando el conjunto *X_train_pca*, entrena un modelo Gradient Boosting y estima la precisión del modelo con una estrategia de *cross-validation* en los mismos conjuntos. Seguidamente calcula las previsiones del modelo en el conjunto *X_test_pca* y su precisión en este conjunto.\n",
    "\n",
    "<hr>\n",
    "Sugerencia: usar los módulos *GradientBoostingClassifier* y *cross_val_score* de sklearn. Para aprender a usar este módulo os recomendamos el siguientes enlace:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "cvscores = cross_val_score(clf, X_train_pca, y_train, cv=5)\n",
    "\n",
    "print(\"Precisión media obtenida con CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))\n",
    "\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "preds_gbc = clf.predict(X_test_pca)\n",
    "\n",
    "# Calcular las probabilidades de cada clase para cada imagen:\n",
    "probs_gbc = clf.predict_proba(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> El boosting se basa en la combinación de clasificadores débiles. En la implementación que utilizaste en este ejercicio, cuál es la profundidad de los árboles utilizados? Compárala con la que utilizaste en los árboles de decisión del ejercicio de *bagging*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "Por defecto en la implementación de sklearn se impone un límite de 3 niveles de profundidad en los árboles usados para el 'boosting', mientras que para el 'bagging' usamos árboles sin límite de profundidad.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Combinación secuencial de clasificadores base diferentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Stacking (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un clasificador de *stacking* usa como atributos las predicciones hechas por otros clasificadores en lugar de los datos originales de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir nuestro clasificador de *stacking* vamos a usar las predicciones hechas en el conjunto de test por los clasificadores:\n",
    "- utilizados en los ejercicios anteriores en la PEC 4\n",
    "- los utilizados en la PEC 3 (K-Nearest neighbors Classifier (knc), Support Vector Machines Classifier (svmc) y Neural Network Classifier (nnc))\n",
    "- Discriminant Analysis (dac)\n",
    "\n",
    "los dos últimos os los damos en archivos adjuntos. Estas predicciones se pueden cargar con el siguiente código: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de predicciones calculadas en la prueba PEC3:\n",
    "preds_knc = np.load(\"preds_knc.pickle\")\n",
    "preds_svmc = np.load(\"preds_svmc.pickle\")\n",
    "preds_nnc = np.load(\"preds_nnc.pickle\")\n",
    "\n",
    "# carga de las predicciones por un modelo de Discriminant Analysis:\n",
    "preds_dac = np.load(\"preds_dac.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Construye un clasificador de *stacking* usando una *Random Forest* que use como atributos a las predicciones hechas en el conjunto de test por los algoritmos k-nn, SVM, red neuronal y  Gradient Boosting. Calcula la precisión del modelo resultante con *cross-validation* en el conjunto de test.\n",
    "\n",
    "<hr>\n",
    "Sugerencia: usar las funciones column_stack de numpy y OneHotEncoder de sklearn para preparar los datos. Para aprender a usar estas funciones  os recomendamos los siguientes enlaces:<br>\n",
    "https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.column_stack.html<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html<br>\n",
    "http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar las predicciones de los distintos clasificadores:\n",
    "X_test_stacking = np.column_stack((preds_rfc, preds_gbc, preds_knc, preds_svmc, preds_nnc, preds_dac))\n",
    "print(\"Dimensiones de la matriz con las predicciones de todos los clasificadores: {}\".format(np.shape(X_test_stacking)))\n",
    "\n",
    "# Transformar las variables categóricas (son todas) con OneHotEncoder:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "enc.fit(X_test_stacking)  \n",
    "X_test_stacking = enc.transform(X_test_stacking).toarray()\n",
    "print(\"Dimensiones de la matriz para entrenar el clasificador de stacking: {}\".format(np.shape(X_test_stacking)))\n",
    "\n",
    "# Calcular la precisión de un RandomForestClassifier con estas variables usando CV:\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "cvscores = cross_val_score(clf, X_test_stacking, y_test, cv=5)\n",
    "print(\"Precisión media obtenida con CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Has conseguido mejorar la precisión gracias al *stacking*? Comenta el resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "La precisión obtenida gracias al 'stacking' es ligeramente superior a la obtenida con el mejor modelo anterior, gradient boosting.<br>\n",
    "Aunque las desviaciones de las precisiones medias con CV son del mismo orden que la mejora obtenida, repitiendo el cálculo para diferentes 'seeds' nos da resultados consistentes en los que el 'stacking' es siempre ligeramente superior.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Cascading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Cascading simple (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El caso de *cascading* es parecido al de *stacking* pero utilizando no solamente las predicciones parciales de los clasificadores base, sino también los datos originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Construye un clasificador de *cascading* usando una *Random Forest* que use como atributos a las predicciones hechas en el conjunto de test por los algoritmos k-nn, SVM, red neuronal y  Gradient Boosting, así como también las variables originales. Calcula la precisión del modelo resultante con *cross-validation* en el conjunto de test.\n",
    "\n",
    "<hr>\n",
    "Sugerencia: Usa el mismo conjunto de datos que en el ejercicio anterior pero añade el conjunto de test original *X_test_pca*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar las predicciones de los distintos clasificadores y las variables originales:\n",
    "X_test_cascading = np.column_stack((X_test_pca, X_test_stacking))\n",
    "print(\"Dimensiones de la matriz: {}\".format(np.shape(X_test_cascading)))\n",
    "\n",
    "# Calcular la precisión de un RandomForestClassifier con estas variables usando CV:\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "cvscores = cross_val_score(clf, X_test_cascading, y_test, cv=5)\n",
    "print(\"Precisión media obtenida con CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Has conseguido mejorar la precisión gracias al *cascading*? Comenta el resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "La precisión obtenida gracias al 'cascading' es equivalente o ligerísimamente superior a la obtenida con 'stacking'. Las desviaciones de las precisiones medias con CV son superiores a mejora obtenida. <br>\n",
    "Repitiendo el cálculo para diferentes 'seeds' vemos que el 'cascading' es consistentemente superior, pero el margen es muy pequeño.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Cascading con variables adicionales (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el *cascading* también podemos añadir como variables del modelo a datos adicionales que se hayan podido generar durante la toma de decisiones de los clasificadores que combinamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Qué datos adicionales de los modelos anteriores podrías usar para enriquecer al modelo? Construye un clasificador de *cascading* usando una *Random Forest* que use como atributos a los usados en el ejercicio anterior más otros que puedas obtener de algunos de los clasificadores utilizados en los ejercicios anteriores. Calcula la precisión del modelo resultante con *cross-validation* en el conjunto de test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga datos:\n",
    "probs_knc = np.load(\"probs_knc.pickle\")\n",
    "probs_svmc = np.load(\"probs_svmc.pickle\")\n",
    "probs_dac = np.load(\"probs_dac.pickle\")\n",
    "\n",
    "# Juntar las predicciones de los distintos clasificadores incluyendo las probabilidades en cada clase:\n",
    "X_test_cascading = np.column_stack((X_test_pca, probs_rfc, probs_gbc, probs_knc, probs_svmc, probs_dac, X_test_stacking))\n",
    "print(\"Dimensiones de la matriz: {}\".format(np.shape(X_test_cascading)))\n",
    "\n",
    "# Calcular la precisión de un RandomForestClassifier con estas variables usando CV:\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "cvscores = cross_val_score(clf, X_test_cascading, y_test, cv=5)\n",
    "print(\"Precisión media obtenida con CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Has conseguido mejorar la precisión gracias a añadir datos adicionales al *stacking*? Comenta el resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Solución:</strong>\n",
    "<br>\n",
    "Hemos añadido las probabilidades de cada clase predichas por cada uno de los modelos como datos adicionales.<br>\n",
    "La precisión obtenida 'stacking' es ligeramente superior a la obtenida anteriormente, aunque esta mejora está dentro de las desviaciones de las precisiones medias con CV.<br>\n",
    "Los datos adicionados aportan nueva información al modelo, que ahora  conoce con qué probabilidad fue prevista cada clase anteriormente, por lo que no nos sorprende que el modelo haya mejorado muy ligeramente.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
